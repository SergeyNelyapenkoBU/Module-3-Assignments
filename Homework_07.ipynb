{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 07: Ensemble Methods – Bagging, Random Forests, and Gradient Boosting\n",
    "\n",
    "## Due: Midnight on March 16 (with 2-hour grace period) and worth 75 points\n",
    "\n",
    "Over the past two weeks, we have expanded our machine learning toolkit by moving beyond linear regression to explore decision trees, which introduced a variety of interacting parameters. Through Homework 6, you developed a systematic workflow for parameter tuning that balances manual exploration and automated searches (e.g., random or grid search) to optimize performance while gaining insights into model behavior.\n",
    "\n",
    "This week, we take another step forward by studying ensemble methods which combine multiple decision trees to produce even stronger predictive models. Specifically, we will investigate:\n",
    "\n",
    "- Bagging  \n",
    "- Random Forests  \n",
    "- Gradient Boosting  \n",
    "\n",
    "These three approaches build on the decision tree we studied last week. Our  workflow from Homework 6 will again serve as the foundation for optimizing these more complex models.\n",
    "\n",
    "### What We Will Do in This Homework\n",
    "\n",
    "To analyze and optimize our ensemble models, we will apply the two-phase strategy introduced in Homework 6 (but with grid search rather than random grid search):\n",
    "\n",
    "1. **First Phase:**  \n",
    "   - Iteratively sweep through key parameters in coarse ranges  \n",
    "   - Visualize training, validation, and test MSE  \n",
    "   - Diagnose overfitting or underfitting  \n",
    "   - Examine the standard deviation of CV scores to understand model stability (review Problems 1 & 2 in Homework 6)\n",
    "\n",
    "2. **Second Phase:**  \n",
    "   - Focus on the most unstable or promising parameter ranges found in Phase 1  \n",
    "   - Perform an exhaustive search within these narrower ranges using `GridSearchCV` (review Problem 4 in Homework 6)\n",
    "\n",
    "Refer to **Appendix 4** for more details.\n",
    "\n",
    "We will follow this process for each of the three ensemble methods, systematically tuning their four most important parameters:\n",
    "\n",
    "1. **Bagging Regressor:** `n_estimators`, `max_samples`, `max_features`, `bootstrap`  \n",
    "2. **Random Forest Regressor:** `n_estimators`, `max_depth`, `max_features`, `bootstrap`  \n",
    "3. **Gradient Boosting Regressor:** `learning_rate`, `n_estimators`, `max_depth`, `max_features`\n",
    "\n",
    "Throughout this homework, we will continue using `RepeatedKFold` cross-validation to reduce variance in our CV MSE estimates. The default number of repetitions is 10, but you may find it necessary to reduce this when initially searching broad parameter spaces—then increase it for fine-tuning as you zero-in on the best models. \n",
    "\n",
    "As before, you will store your best parameter values (and the resulting CV MSE) in a dictionary in order to track improvements across experiments and maintain a clear record of how each parameter choice was made.\n",
    "\n",
    "Before starting:\n",
    "- Review lesson materials on ensemble methods and watch the three videos on Bagging, Random Forests, and Gradient Boosting.  \n",
    "- Study the relevant appendices.  \n",
    "- Pay special attention to the Gradient Boosting video and notebook, as the code in this homework builds on (and has been adapted from) those resources.\n",
    "\n",
    "### Grading\n",
    "\n",
    "This homework consists of 15 graded problems, each worth 5 points, for a total of 75 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful imports\n",
    "\n",
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "import time\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold,GridSearchCV\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics         import mean_squared_error\n",
    "from tqdm                    import tqdm\n",
    "\n",
    "import matplotlib.ticker as mticker           # Optional: you can print out y axis labels as dollars. \n",
    "\n",
    "# globals\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# utility code\n",
    "\n",
    "# Completely optional:  Format y-axis labels as dollars with commas\n",
    "def dollar_format(x, pos):\n",
    "    return f'${x:,.0f}'\n",
    "\n",
    "def format_hms(seconds):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Ames Housing Dataset  \n",
    "\n",
    "The code cell below will load the dataset for you.  This is the same dataset we used for the last two homeworks. \n",
    "\n",
    "> **Notice** that this code includes a useful optimization: **before downloading, it first\n",
    "checks whether the files already exist.** This is a essential step when working with large datasets or when building deep learning models, where training can span hours or even days. By reusing previously downloaded files or saved models, you can avoid unnecessary work and significantly speed up your workflow.\n",
    "\n",
    "For a detailed description of the dataset features, please refer to the **Appendix** in Homework 05. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset files already exist. Skipping download.\n",
      "Training and testing datasets loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"Ames_Dataset\"                              # Directory where files will be stored\n",
    "\n",
    "# Check if one of the files exists; if not, download and extract the zip file\n",
    "\n",
    "if not os.path.exists( os.path.join(data_dir, \"X_train.csv\") ):\n",
    "    print(\"Dataset files not found. Downloading...\")\n",
    "    zip_url = \"https://www.cs.bu.edu/fac/snyder/cs505/Data/ames_housing.zip\"\n",
    "    try:\n",
    "        response = requests.get(zip_url)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        # Extract the zip file into the designated directory\n",
    "        with zipfile.ZipFile(io.BytesIO(response.content)) as zipf:\n",
    "            zipf.extractall(data_dir)\n",
    "        print(\"Files downloaded and extracted successfully.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading the file: {e}\")\n",
    "else:\n",
    "    print(\"Dataset files already exist. Skipping download.\")\n",
    "\n",
    "# Load the datasets\n",
    "X_train = pd.read_csv(os.path.join(data_dir, \"X_train.csv\"))\n",
    "X_test  = pd.read_csv(os.path.join(data_dir, \"X_test.csv\"))\n",
    "y_train = pd.read_csv(os.path.join(data_dir, \"y_train.csv\")).squeeze(\"columns\")    \n",
    "y_test  = pd.read_csv(os.path.join(data_dir, \"y_test.csv\")).squeeze(\"columns\")\n",
    "\n",
    "print(\"Training and testing datasets loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelude: Wrapper Functions for Running Ensemble Models\n",
    "\n",
    "The following cells are adapted from the Week 7 video notebook on `GradientBoostingRegressor`, but have been refactored so that they can handle any of the three ensemble models (Bagging, Random Forest, or Gradient Boosting). Key changes include:\n",
    "\n",
    "- **`run_model`** replaces the original `run_gradient_boosting_regressor` and accepts a parameter dictionary that can be applied to any of the three ensemble models.  \n",
    "- **`sweep_parameter`** is updated to work seamlessly with `run_model`, letting you:\n",
    "  - Specify which ensemble model you want to use.  \n",
    "  - Pass a dictionary of model parameters.  \n",
    "  - Return a modified parameter dictionary reflecting the best value of the parameter you swept, along with the corresponding MSE  (note that RMSE is **only** used for printing out results)\n",
    "\n",
    "> **Note:** Please do not change these cells unless you consult with the LFs first. Any alterations may cause downstream issues with the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repeats = 2\n",
    "emulate = False\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=n_repeats, random_state=42)\n",
    "splits = list(rkf.split(X_train, y_train))  # This stores the indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def run_model(model, X_train, y_train, X_test, y_test, n_repeats=n_repeats, n_jobs=-1, **model_params):\n",
    "\n",
    "    # Remove non-model keys\n",
    "    for key in ['MSE_found', 'RMSE_found']:\n",
    "        model_params.pop(key, None)\n",
    "    \n",
    "    if isinstance(model, type):\n",
    "        model = model(**model_params)\n",
    "    else:\n",
    "        model.set_params(**model_params)\n",
    "\n",
    "    neg_mse_scores = cross_val_score(model, X_train, y_train,scoring = 'neg_mean_squared_error',\n",
    "                                     #cv = RepeatedKFold(n_splits=5, n_repeats=n_repeats, random_state=42), \n",
    "                                     #cv = 5,\n",
    "                                     cv = splits,\n",
    "                                     n_jobs  = n_jobs)\n",
    "    \n",
    "    mean_cv_mse = -np.mean(neg_mse_scores)\n",
    "    std_cv_mse  = np.std(neg_mse_scores)\n",
    "    \n",
    "    # Fit the model on the full training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Compute training MSE and testing MSE\n",
    "    train_preds = model.predict(X_train)\n",
    "    train_mse   = mean_squared_error(y_train, train_preds)\n",
    "    test_preds  = model.predict(X_test)\n",
    "    test_mse    = mean_squared_error(y_test, test_preds)\n",
    "    \n",
    "    return mean_cv_mse, std_cv_mse, train_mse, test_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_parameter(model,\n",
    "                    Parameters,\n",
    "                    param,\n",
    "                    parameter_list,\n",
    "                    X_train          = X_train,\n",
    "                    y_train          = y_train,\n",
    "                    X_test           = X_test,\n",
    "                    y_test           = y_test,\n",
    "                    verbose          = True,\n",
    "                    show_rmse        = True,\n",
    "                    n_iter_no_change = None,\n",
    "                    delta            = 0.001,\n",
    "                    n_jobs           = -1,\n",
    "                    n_repeats        = n_repeats):\n",
    "    \n",
    "    \n",
    "    Parameters = Parameters.copy()  # Avoid modifying the original dictionary\n",
    "    \n",
    "    print(f\"Emulation mode: {emulate}\")   \n",
    "    if emulate is True:\n",
    "        Parameters['MSE_found'] = 30000**2 + 1000 * random.random()\n",
    "        print(f\"Emulation mode parameters: {Parameters}\")   \n",
    "        return Parameters\n",
    "       \n",
    "         \n",
    "    start = time.time()\n",
    "    \n",
    "  \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    cv_mses, std_cvs, train_mses, test_mses = [], [], [], []\n",
    "    no_improve_count = 0\n",
    "    best_mse = float('inf')\n",
    "    \n",
    "    # Run over each value in parameter_list\n",
    "    for p in tqdm(parameter_list, desc=f\"Sweeping {param}\"):\n",
    "        Parameters[param] = p\n",
    "        P_temp = Parameters.copy()\n",
    "        # Remove MSE_found if present, just in case\n",
    "        P_temp.pop('MSE_found', None)\n",
    "        P_temp.pop('RMSE_found', None)\n",
    "        \n",
    "        cv_mse, std_cv, train_mse, test_mse = run_model(\n",
    "            model=model,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test,   y_test=y_test,\n",
    "            n_repeats=n_repeats,\n",
    "            n_jobs=n_jobs,\n",
    "            **P_temp\n",
    "        )\n",
    "        cv_mses.append(cv_mse)\n",
    "        std_cvs.append(std_cv)\n",
    "        train_mses.append(train_mse)\n",
    "        test_mses.append(test_mse)\n",
    "        \n",
    "        # Early-stopping logic\n",
    "        if cv_mse < best_mse - delta:\n",
    "            best_mse = cv_mse\n",
    "            no_improve_count = 0\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "        \n",
    "        if n_iter_no_change is not None and no_improve_count >= n_iter_no_change:\n",
    "            print(f\"Early stopping: No improvement after {n_iter_no_change} iterations.\")\n",
    "            break\n",
    "    \n",
    "    # Identify best parameter\n",
    "    min_cv_mse = min(cv_mses)\n",
    "    min_index = cv_mses.index(min_cv_mse)\n",
    "    best_param = parameter_list[min_index]\n",
    "    Parameters[param] = best_param\n",
    "    Parameters['MSE_found'] = min_cv_mse\n",
    "    \n",
    "    if verbose:\n",
    "        # Prepare for plotting\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8), sharex=True)\n",
    "        \n",
    "        # We only need as many parameter values as we actually computed\n",
    "        partial_param_list = parameter_list[:len(cv_mses)]\n",
    "        \n",
    "        # Check if our parameter list is Boolean so we can label accordingly\n",
    "        is_boolean = all(isinstance(val, bool) for val in partial_param_list)\n",
    "        if is_boolean:\n",
    "            # Convert booleans to integer indices for plotting\n",
    "            x_vals = list(range(len(partial_param_list)))\n",
    "            x_labels = [str(val) for val in partial_param_list]\n",
    "        else:\n",
    "            # Treat numeric or other types as-is\n",
    "            x_vals = partial_param_list\n",
    "            x_labels = partial_param_list\n",
    "        \n",
    "        error_name = 'RMSE' if show_rmse else 'MSE'\n",
    "        \n",
    "        # ----- First plot: (R)MSE -----\n",
    "        ax1.set_title(f\"{error_name} vs {param}\")\n",
    "        \n",
    "        # Apply dollar formatting ONLY if we're showing RMSE\n",
    "        if show_rmse:\n",
    "            ax1.yaxis.set_major_formatter(mticker.FuncFormatter(dollar_format))\n",
    "        \n",
    "        # Plot lines\n",
    "        ax1.plot(x_vals,\n",
    "                 np.sqrt(cv_mses) if show_rmse else cv_mses,\n",
    "                 marker='.', label=f\"CV {error_name}\", color='blue')\n",
    "        ax1.plot(x_vals,\n",
    "                 np.sqrt(train_mses) if show_rmse else train_mses,\n",
    "                 marker='.', label=f\"Train {error_name}\", color='green')\n",
    "        ax1.plot(x_vals,\n",
    "                 np.sqrt(test_mses) if show_rmse else test_mses,\n",
    "                 linestyle='--', label=f\"Test {error_name}\", color='orange')\n",
    "        ax1.scatter([x_vals[min_index]],\n",
    "                    [np.sqrt(min_cv_mse) if show_rmse else min_cv_mse], s = 100 ,\n",
    "                    marker='x', label=f\"Best CV {error_name}\", color='red')\n",
    "        \n",
    "        ax1.set_ylabel(error_name)\n",
    "        ax1.legend()\n",
    "        ax1.grid()\n",
    "        \n",
    "        # ----- Second plot: CV Std Dev -----\n",
    "        ax2.set_title(f\"CV Standard Deviation vs {param}\")\n",
    "        ax2.plot(x_vals, std_cvs, marker='.', label=f\"CV {error_name} Std\", color='blue')\n",
    "        ax2.set_xlabel(param)\n",
    "        ax2.set_ylabel(\"Standard Deviation\")\n",
    "        ax2.legend()\n",
    "        ax2.grid(alpha=0.5)\n",
    "        \n",
    "        # If we are using boolean x-values, set custom ticks\n",
    "        if is_boolean:\n",
    "            ax2.set_xticks(x_vals)\n",
    "            ax2.set_xticklabels(x_labels)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        end = time.time()\n",
    "        print(\"Execution Time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end - start)))\n",
    "    \n",
    "    return Parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Problem One: Bagging Trees**  \n",
    "\n",
    "In this problem, you will follow a structured workflow to tune and evaluate a **Bagging Regressor**. The process builds on the approach from the last two homeworks; note that, as Homework 06, we will apply **grid search** to systematically explore parameter values.  Note that we will **not** be used Early Stopping in this homework; this will be a valuable technique going forward, but in this homework we are still learning how these complex models perform.\n",
    "\n",
    "At the end of the analysis, you will not simply select the model with the lowest CV MSE score. Instead, you will critically examine the plots to determine whether another model configuration provides a better balance between performance, stability, and generalization. This step is essential for ensuring that your chosen model will perform well on new data. The criteria we will use for this choice are in **Appendix 5** below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1.A: Iteratively Sweep Parameters and Visualize Results using `sweep_parameter(...)`**  \n",
    "We will start with the `Default_Parameters_Bagging` dictionary and iteratively adjust key parameters. At each step, using the code provided above, you will:  \n",
    "\n",
    "- Test a range of values for the specified parameter.\n",
    "- Plot training, repeated cross-validation, and test MSE to diagnose overfitting or underfitting.\n",
    "- Plot the standard deviation of the CV scores to assess model stability.\n",
    "- Store the best value (which produces the minimum CV MSE) in a dictionary, perhaps called `Parameters_BT`.\n",
    "\n",
    "**You should read Appendix 4 now if you have not done so already.**\n",
    "\n",
    "**Step-by-step process:**\n",
    "1. **Sweep `n_estimators`** (integer values):  \n",
    "   - Begin by *making a copy* of the provided `Default_Parameters_Bagging` dictionary.  \n",
    "   - Sweep a range of **integer** values for `n_estimators` (the number of base learners).  \n",
    "   - Store the best value in `Parameters_BT`. \n",
    "\n",
    "2. **Sweep `max_samples`** (float values):  \n",
    "   - Using `Parameters_BT`, test a range of **float** values for `max_samples`.  \n",
    "   - Store the best value in `Parameters_BT`. (*Note: This may simply be the default value!*)\n",
    "\n",
    "3. **Sweep `max_features`** (integer values):  \n",
    "   - Using `Parameters_BT`, test a range of **integer** values for `max_features`.  \n",
    "   - Store the best value in `Parameters_BT`. (*Again, the best value might be the default!*)\n",
    "\n",
    "4. **Sweep `bootstrap`** (Boolean values):  \n",
    "   - Test both possible values (`True` and `False`).  \n",
    "   - Store the best value in `Parameters_BT`.\n",
    "\n",
    "5. **Report your final results (including all final parameter choices, and convert MSE to RMSE in dollars when printing out)** and answer the graded question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the BaggingRegressor\n",
    "Default_Parameters_Bagging = {\n",
    "    'n_estimators': 10,            # Number of base estimators in the ensemble\n",
    "    'max_samples' : 1.0,           # Fraction of samples to draw for each base estimator\n",
    "    'max_features': 1.0,           # Fraction of features to consider for each estimator\n",
    "    'bootstrap'   : True,          # Use bootstrap samples when building estimators\n",
    "    'random_state': 42,            # Ensures reproducibility\n",
    "    'MSE_found'   : float('inf')   # Used for tracking the best MSE during parameter sweeps, to record result of these parameter choices\n",
    "                                   # Initialized to inf in case want to use this to record best MSE found so far in a sequence of parameter choices\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some global variables for the parameter sweeps\n",
    "augmented_bagging_result_list = []\n",
    "augmented_bagging_result = []\n",
    "Parameters_BT_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = 'logs/hw07_log'\n",
    "def log_message(text, log_file=log_file):\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    log_entry = f\"[{timestamp}] {text}\"\n",
    "    log_file = log_file + datetime.datetime.now().strftime('%Y%m%d') + '.log'\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(log_entry + '\\n')\n",
    "\n",
    "\n",
    "# log_message(f'{augmented_bagging_result}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. All defaults: \n",
    "model_all_defaults = BaggingRegressor\n",
    "P_temp = Default_Parameters_Bagging.copy()\n",
    "cv_mse, std_cv, train_mse, test_mse = run_model(\n",
    "            model=model_all_defaults,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test,   y_test=y_test,\n",
    "            n_repeats=n_repeats,\n",
    "            n_jobs=-1,\n",
    "            **P_temp\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_rmse: 28227.017087976972,cv_mse: 796764493.6849439, std_cv: 222077367.8200688, train_mse: 163747881.66543517, test_mse: 859097201.1368771\n",
      "defaults: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': np.float64(796764493.6849439), 'RMSE_found': np.float64(28227.017087976972)}\n"
     ]
    }
   ],
   "source": [
    "all_defaults_cv_rmse = np.sqrt(cv_mse)\n",
    "print(f\"cv_rmse: {all_defaults_cv_rmse},cv_mse: {cv_mse}, std_cv: {std_cv}, train_mse: {train_mse}, test_mse: {test_mse}\")\n",
    "\n",
    "# Lists:\n",
    "augmented_bagging_result = Default_Parameters_Bagging.copy()\n",
    "augmented_bagging_result['MSE_found']=cv_mse\n",
    "augmented_bagging_result['RMSE_found']=all_defaults_cv_rmse\n",
    "augmented_bagging_result_list.append(augmented_bagging_result)\n",
    "print(f\"defaults: {augmented_bagging_result}\")\n",
    "\n",
    "Parameters_BT_list.append(Default_Parameters_Bagging)\n",
    "log_message(f'defaults: {augmented_bagging_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000412.7423962}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 1. Sweep n_estimators:\n",
    "n_repeats=2\n",
    "part_name = '1.A'\n",
    "param = 'n_estimators'\n",
    "parameter_list = range(1,1000,50)   \n",
    "model = BaggingRegressor\n",
    "default_parameters = Default_Parameters_Bagging.copy()\n",
    "\n",
    "# Run bagging:\n",
    "bagging_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_bagging_result: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000412.7423962, 'param': 'n_estimators', 'part_name': '1.A', 'RMSE_found': np.float64(30000.00687903915)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_bagging_result = bagging_result.copy()\n",
    "Parameters_BT = bagging_result.copy()\n",
    "augmented_bagging_result['param'] = param\n",
    "augmented_bagging_result['part_name'] = part_name\n",
    "augmented_bagging_result['RMSE_found'] = np.sqrt(bagging_result['MSE_found'])\n",
    "print(f\"augmented_bagging_result: {augmented_bagging_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_bagging_result_list.append(augmented_bagging_result)\n",
    "log_message(f'{augmented_bagging_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune the model, manually overriding the defaults or the best parameters found so far\n",
    "# 1. n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000288.0638434}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 2. Sweep max_samples:\n",
    "model = BaggingRegressor\n",
    "param = 'max_samples'\n",
    "parameter_list = np.linspace(0.1,1.0,10)  # Add 1 to the last element to include 1 as integer\n",
    "default_parameters = Parameters_BT.copy()\n",
    "\n",
    "bagging_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_bagging_result: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000288.0638434, 'param': 'max_samples', 'part_name': '1.A', 'RMSE_found': np.float64(30000.00480106367)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_bagging_result = bagging_result.copy()\n",
    "Parameters_BT = bagging_result.copy()\n",
    "augmented_bagging_result['param'] = param\n",
    "augmented_bagging_result['part_name'] = part_name\n",
    "augmented_bagging_result['RMSE_found'] = np.sqrt(bagging_result['MSE_found'])\n",
    "print(f\"augmented_bagging_result: {augmented_bagging_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_bagging_result_list.append(augmented_bagging_result)\n",
    "log_message(f'{augmented_bagging_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune the model, manually overriding the defaults or the best parameters found so far\n",
    "# 1. max_samples: 1.0 gets better results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2344, 73)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000807.8806218}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 3. Sweep max_features:\n",
    "model = BaggingRegressor\n",
    "param = 'max_features'\n",
    "parameter_list = range(1,74)\n",
    "default_parameters = Parameters_BT.copy()\n",
    "\n",
    "bagging_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_bagging_result: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000807.8806218, 'param': 'max_features', 'part_name': '1.A', 'RMSE_found': np.float64(30000.013464674008)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_bagging_result = bagging_result.copy()\n",
    "Parameters_BT = bagging_result.copy()\n",
    "augmented_bagging_result['param'] = param\n",
    "augmented_bagging_result['part_name'] = part_name\n",
    "augmented_bagging_result['RMSE_found'] = np.sqrt(bagging_result['MSE_found'])\n",
    "print(f\"augmented_bagging_result: {augmented_bagging_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_bagging_result_list.append(augmented_bagging_result)\n",
    "log_message(f'{augmented_bagging_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000415.6085284}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 3. Sweep bootstrap:\n",
    "model = BaggingRegressor\n",
    "param = 'bootstrap'\n",
    "parameter_list = [True, False]\n",
    "default_parameters = Parameters_BT.copy()\n",
    "\n",
    "bagging_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_bagging_result: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000415.6085284, 'param': 'bootstrap', 'part_name': '1.A', 'RMSE_found': np.float64(30000.006926808008)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_bagging_result = bagging_result.copy()\n",
    "Parameters_BT = bagging_result.copy()\n",
    "augmented_bagging_result['param'] = param\n",
    "augmented_bagging_result['part_name'] = part_name\n",
    "augmented_bagging_result['RMSE_found'] = np.sqrt(bagging_result['MSE_found'])\n",
    "print(f\"augmented_bagging_result: {augmented_bagging_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_bagging_result_list.append(augmented_bagging_result)\n",
    "log_message(f'{augmented_bagging_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>max_features</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>random_state</th>\n",
       "      <th>MSE_found</th>\n",
       "      <th>RMSE_found</th>\n",
       "      <th>param</th>\n",
       "      <th>part_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>7.967645e+08</td>\n",
       "      <td>28227.017088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000004e+08</td>\n",
       "      <td>30000.006879</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>1.A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000003e+08</td>\n",
       "      <td>30000.004801</td>\n",
       "      <td>max_samples</td>\n",
       "      <td>1.A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000008e+08</td>\n",
       "      <td>30000.013465</td>\n",
       "      <td>max_features</td>\n",
       "      <td>1.A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000004e+08</td>\n",
       "      <td>30000.006927</td>\n",
       "      <td>bootstrap</td>\n",
       "      <td>1.A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  max_samples  max_features  bootstrap  random_state  \\\n",
       "0            10          1.0           1.0       True            42   \n",
       "1            10          1.0           1.0       True            42   \n",
       "2            10          1.0           1.0       True            42   \n",
       "3            10          1.0           1.0       True            42   \n",
       "4            10          1.0           1.0       True            42   \n",
       "\n",
       "      MSE_found    RMSE_found         param part_name  \n",
       "0  7.967645e+08  28227.017088           NaN       NaN  \n",
       "1  9.000004e+08  30000.006879  n_estimators       1.A  \n",
       "2  9.000003e+08  30000.004801   max_samples       1.A  \n",
       "3  9.000008e+08  30000.013465  max_features       1.A  \n",
       "4  9.000004e+08  30000.006927     bootstrap       1.A  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1a_Parameters_BT_df = pd.DataFrame(Parameters_BT_list)\n",
    "\n",
    "p1a_augmented_bagging_result_df = pd.DataFrame(augmented_bagging_result_list)\n",
    "p1a_augmented_bagging_result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(28227.017087976972)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p1a_augmented_bagging_result_df['RMSE_found'].idxmin())\n",
    "RMSE_part1A = p1a_augmented_bagging_result_df['RMSE_found'].min()\n",
    "RMSE_part1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameters_BT_p1a = Parameters_BT_list[p1a_Parameters_BT_df['MSE_found'].idxmin()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.A Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1a = $28,227.02\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to best CV RMSE score found after Part A\n",
    "\n",
    "a1a = RMSE_part1A     # Just to get it to run without error; your answer here (remember to use the RMSE)         \n",
    "\n",
    "print(f'a1a = ${a1a:,.2f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1.B: Refine Parameters for Model Stability**  \n",
    "After completing the first sweep, **repeat Part A as needed** to refine your model.  \n",
    "- Your goal is to identify the parameter combination that minimizes the **CV MSE**.  \n",
    "- **Final tuning goals:**\n",
    "  - Adjust `n_estimators` with a **tolerance of 10**.\n",
    "  - Adjust `max_samples` with a **tolerance of 0.1**.\n",
    "  - Adjust `max_features` with a **tolerance of 1**.\n",
    "- **Report your final results (including all final parameter choices, and convert MSE to RMSE in dollars when printing out)** and answer the graded question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters_BT: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000288.0638434}\n"
     ]
    }
   ],
   "source": [
    "# Get best parameters from Part A:\n",
    "Parameters_BT = Parameters_BT_list[p1a_Parameters_BT_df['MSE_found'].idxmin()].copy()\n",
    "print(f\"Parameters_BT: {Parameters_BT}\")\n",
    "Parameters_BT_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune the model, manually overriding the defaults or the best parameters found so far\n",
    "# 1. max_samples: 1.0 gets better results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000880.5514169}\n"
     ]
    }
   ],
   "source": [
    "# Your code here:\n",
    "\n",
    "augmented_bagging_result = []\n",
    "augmented_bagging_result_list = []\n",
    "Parameters_BT_list = []\n",
    "\n",
    "# Set variables:\n",
    "part_name = '1.B'\n",
    "param = 'n_estimators'\n",
    "parameter_list = range(80,200,10)   \n",
    "model = BaggingRegressor\n",
    "default_parameters = Parameters_BT.copy()\n",
    "\n",
    "# Run bagging:\n",
    "bagging_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_bagging_result: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000880.5514169, 'param': 'n_estimators', 'part_name': '1.B', 'RMSE_found': np.float64(30000.01467585336)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_bagging_result = bagging_result.copy()\n",
    "Parameters_BT = bagging_result.copy()\n",
    "augmented_bagging_result['param'] = param\n",
    "augmented_bagging_result['part_name'] = part_name\n",
    "augmented_bagging_result['RMSE_found'] = np.sqrt(bagging_result['MSE_found'])\n",
    "print(f\"augmented_bagging_result: {augmented_bagging_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_bagging_result_list.append(augmented_bagging_result)\n",
    "log_message(f'{augmented_bagging_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000811.0187038}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "part_name = '1.B'\n",
    "param = 'max_samples'\n",
    "parameter_list = np.linspace(0.5,1.0,10) \n",
    "model = BaggingRegressor\n",
    "default_parameters = Parameters_BT.copy()\n",
    "\n",
    "# Run bagging:\n",
    "bagging_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_bagging_result: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000811.0187038, 'param': 'max_samples', 'part_name': '1.B', 'RMSE_found': np.float64(30000.013516975352)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_bagging_result = bagging_result.copy()\n",
    "Parameters_BT = bagging_result.copy()\n",
    "augmented_bagging_result['param'] = param\n",
    "augmented_bagging_result['part_name'] = part_name\n",
    "augmented_bagging_result['RMSE_found'] = np.sqrt(bagging_result['MSE_found'])\n",
    "print(f\"augmented_bagging_result: {augmented_bagging_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_bagging_result_list.append(augmented_bagging_result)\n",
    "log_message(f'{augmented_bagging_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000219.6671956}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "part_name = '1.B'\n",
    "param = 'max_features'\n",
    "parameter_list = range(35,60)\n",
    "model = BaggingRegressor\n",
    "default_parameters = Parameters_BT.copy()\n",
    "\n",
    "# Run bagging:\n",
    "bagging_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_bagging_result: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000219.6671956, 'param': 'max_features', 'part_name': '1.B', 'RMSE_found': np.float64(30000.003661119703)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_bagging_result = bagging_result.copy()\n",
    "Parameters_BT = bagging_result.copy()\n",
    "augmented_bagging_result['param'] = param\n",
    "augmented_bagging_result['part_name'] = part_name\n",
    "augmented_bagging_result['RMSE_found'] = np.sqrt(bagging_result['MSE_found'])\n",
    "print(f\"augmented_bagging_result: {augmented_bagging_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_bagging_result_list.append(augmented_bagging_result) \n",
    "log_message(f'{augmented_bagging_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000227.4262068}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "part_name = '1.B'\n",
    "param = 'bootstrap'\n",
    "parameter_list = [True, False]\n",
    "model = BaggingRegressor\n",
    "default_parameters = Parameters_BT.copy()\n",
    "\n",
    "# Run bagging:\n",
    "bagging_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_bagging_result: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000227.4262068, 'param': 'bootstrap', 'part_name': '1.B', 'RMSE_found': np.float64(30000.00379043654)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_bagging_result = bagging_result.copy()\n",
    "Parameters_BT = bagging_result.copy()\n",
    "augmented_bagging_result['param'] = param\n",
    "augmented_bagging_result['part_name'] = part_name\n",
    "augmented_bagging_result['RMSE_found'] = np.sqrt(bagging_result['MSE_found'])\n",
    "print(f\"augmented_bagging_result: {augmented_bagging_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_bagging_result_list.append(augmented_bagging_result) \n",
    "log_message(f'{augmented_bagging_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>max_features</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>random_state</th>\n",
       "      <th>MSE_found</th>\n",
       "      <th>param</th>\n",
       "      <th>part_name</th>\n",
       "      <th>RMSE_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000009e+08</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>1.B</td>\n",
       "      <td>30000.014676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000008e+08</td>\n",
       "      <td>max_samples</td>\n",
       "      <td>1.B</td>\n",
       "      <td>30000.013517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000002e+08</td>\n",
       "      <td>max_features</td>\n",
       "      <td>1.B</td>\n",
       "      <td>30000.003661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000002e+08</td>\n",
       "      <td>bootstrap</td>\n",
       "      <td>1.B</td>\n",
       "      <td>30000.003790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators  max_samples  max_features  bootstrap  random_state  \\\n",
       "0            10          1.0           1.0       True            42   \n",
       "1            10          1.0           1.0       True            42   \n",
       "2            10          1.0           1.0       True            42   \n",
       "3            10          1.0           1.0       True            42   \n",
       "\n",
       "      MSE_found         param part_name    RMSE_found  \n",
       "0  9.000009e+08  n_estimators       1.B  30000.014676  \n",
       "1  9.000008e+08   max_samples       1.B  30000.013517  \n",
       "2  9.000002e+08  max_features       1.B  30000.003661  \n",
       "3  9.000002e+08     bootstrap       1.B  30000.003790  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1b_augmented_bagging_result_df = pd.DataFrame(augmented_bagging_result_list)\n",
    "p1b_augmented_bagging_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000219.6671956, 'param': 'max_features', 'part_name': '1.B', 'RMSE_found': np.float64(30000.003661119703)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(30000.003661119703)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p1b_augmented_bagging_result_df['RMSE_found'].idxmin())\n",
    "print(augmented_bagging_result_list[p1b_augmented_bagging_result_df['RMSE_found'].idxmin()])\n",
    "Parameters_BT_p1b = Parameters_BT_list[p1b_augmented_bagging_result_df['RMSE_found'].idxmin()].copy()\n",
    "RMSE_part1B = p1b_augmented_bagging_result_df['RMSE_found'].min()\n",
    "RMSE_part1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_part1A: 28227.017087976972\n",
      "RMSE_part1B: 30000.003661119703\n",
      "Failure!: RMSE_part1B: 30,000.00 is greater than RMSE_part1A: 28,227.02\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE_part1A: {RMSE_part1A}\")\n",
    "print(f\"RMSE_part1B: {RMSE_part1B}\")\n",
    "\n",
    "if RMSE_part1B < RMSE_part1A:\n",
    "    print(f\"Success!: RMSE_part1B: {RMSE_part1B:,.2f} is less than RMSE_part1A: {RMSE_part1A:,.2f}\")\n",
    "else:\n",
    "    print(f\"Failure!: RMSE_part1B: {RMSE_part1B:,.2f} is greater than RMSE_part1A: {RMSE_part1A:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.B Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1b = $30,000.00\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to best CV RMSE score found after Part B (it may not be different than Part A)\n",
    "\n",
    "a1b = RMSE_part1B                        # Just to get it to run without error; your answer here (remember to use the RMSE)          \n",
    "\n",
    "print(f'a1b = ${a1b:,.2f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1.C: Use `GridSearchCV` for Exhaustive Search**  \n",
    "Once you have completed your parameter sweeps in Part B, you will verify and perhaps even refine your results using exhaustive grid search (not random search). \n",
    "- In your results from Part B, identify **unstable parameter ranges** (review Problem 4 from Homework 06).\n",
    "- Perform  **exhaustive grid searches** within appropriately restricted ranges using `GridSearchCV`.  \n",
    "- **Print out the best result found by exhaustive search (including the final parameter choices, and convert MSE to RMSE in dollars)** and answer the graded question.\n",
    "\n",
    "NOTE: Do *not* simply redo all of Parts A and B, and you should repeat your grid search runs using the techniques described in Appendix 4 until you are sure you have either verified your results from Part B or found a model with an even lower CV MSE score than you found in Part B.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search Results (Top 5):\n",
      "\n",
      " n_estimators  max_samples  max_features  mean_cv_score  std_cv_score  mean_train_score  std_train_score\n",
      "          640          1.0            36   5.843985e+08  7.821016e+07       5573.773317      2754.052959\n",
      "          680          1.0            36   5.846191e+08  7.855562e+07       5688.858401      2823.512795\n",
      "          670          1.0            36   5.847025e+08  7.852141e+07       5659.198442      2798.972636\n",
      "          650          1.0            36   5.847428e+08  7.805592e+07       5570.466511      2753.069876\n",
      "          660          1.0            36   5.851146e+08  7.868271e+07       5647.155187      2799.303158\n",
      "\n",
      "Best Parameters: {'bootstrap': np.False_, 'max_features': 36, 'max_samples': np.float64(1.0), 'n_estimators': 640}\n",
      "Best CV MSE: 584398483.2509\n",
      "Best CV RMSE: 24174.3352\n",
      "Test MSE:    663966251.4008\n",
      "Execution Time: 00:07:23\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# {'n_estimators': 680, 'max_samples': np.float64(0.9444444444444444), 'max_features': 35, 'bootstrap': False, 'random_state': 42, 'MSE_found': np.float64(636096733.8395892), 'param': 'max_features', 'part_name': '1.B', 'RMSE_found': np.float64(25220.9582260387)}\n",
    "\n",
    "# Run GridSearchCV\n",
    "\n",
    "# Record start time\n",
    "start = time.time()\n",
    "\n",
    "# Define the model\n",
    "bagging_model = BaggingRegressor(\n",
    "    random_state=random_state)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': range(640,700,10),          \n",
    "    'max_samples' : np.linspace(0.8,1.0,5),\n",
    "    'bootstrap': np.array([True, False]),\n",
    "    'max_features': [36]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best parameters\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator=bagging_model,\n",
    "    param_grid=param_dist,\n",
    "    scoring='neg_mean_squared_error',  # MSE but negated for maximization by GridSearchCV\n",
    "    cv=5,  # Number of folds for cross-validation -- Reduce this if efficiency is an issue\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Or RandomizedSearchCV -- not as accurate but faster\n",
    "\n",
    "# search = RandomizedSearchCV(\n",
    "#     estimator=bagging_model,\n",
    "#     param_distributions=param_dist,\n",
    "#     n_iter=20,  # Number of random combinations to test\n",
    "#     scoring='neg_mean_squared_error',  # MSE but negated for maximization by RandomizedSearchCV\n",
    "#     cv=5,  # Number of folds for cross-validation\n",
    "#     n_jobs=-1,  # Use all available cores\n",
    "#     random_state=random_state\n",
    "# )\n",
    "\n",
    "# Fit the GridSearchCV\n",
    "search.fit(X_train, y_train)  \n",
    "\n",
    "# Extract results into a DataFrame\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "# Select relevant columns for readability\n",
    "results = results[[\n",
    "    'param_n_estimators',\n",
    "    'param_max_samples',\n",
    "    'param_max_features',\n",
    "    'mean_test_score',\n",
    "    'std_test_score',\n",
    "    'mean_train_score',  # Include training score\n",
    "    'std_train_score',   # Include standard deviation of training score\n",
    "    'rank_test_score'\n",
    "]]\n",
    "\n",
    "# Convert negative MSE to positive\n",
    "results['mean_test_score'] = -results['mean_test_score']\n",
    "results['mean_train_score'] = -results['mean_train_score']\n",
    "\n",
    "# Sort by rank (best scores first)\n",
    "results = results.sort_values(by='rank_test_score')\n",
    "\n",
    "# Rename columns for printing only\n",
    "renamed_results = results.rename(\n",
    "    columns={\n",
    "        'param_n_estimators': 'n_estimators',\n",
    "        'param_max_samples': 'max_samples',\n",
    "        'param_max_features': 'max_features',\n",
    "        'mean_test_score': 'mean_cv_score',\n",
    "        'std_test_score': 'std_cv_score',\n",
    "        'mean_train_score': 'mean_train_score',\n",
    "        'std_train_score': 'std_train_score'\n",
    "    }\n",
    ").drop(columns=['rank_test_score'])  # Drop the rank column for readability\n",
    "\n",
    "# Print the results as a table\n",
    "print(\"\\nSearch Results (Top 5):\\n\")\n",
    "print(renamed_results.head(5).to_string(index=False))  # Show the top 5 results with new headers\n",
    "\n",
    "# Best parameters and test performance\n",
    "print(f\"\\nBest Parameters: {search.best_params_}\")\n",
    "print(f\"Best CV MSE: {-search.best_score_:.4f}\")\n",
    "\n",
    "print(f\"Best CV RMSE: {np.sqrt(-search.best_score_):.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_bagging = search.best_estimator_.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred_bagging)\n",
    "\n",
    "print(f\"Test MSE:    {test_mse:.4f}\")\n",
    "\n",
    "# Record end time and execution time\n",
    "end = time.time()\n",
    "print(\"Execution Time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_df = pd.DataFrame(search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_max_bootstrap = sorted(grid_results_df['param_bootstrap'].unique())\n",
    "\n",
    "for max_boot in unique_max_bootstrap:\n",
    "    subset = grid_results_df[grid_results_df['param_bootstrap'] == max_boot]\n",
    "    \n",
    "    pivot_table = subset.pivot_table(\n",
    "        values='mean_test_score',\n",
    "        index='param_max_samples',\n",
    "        columns='param_n_estimators'\n",
    "    )\n",
    "    pivot_table_rmse = np.sqrt(-pivot_table)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(pivot_table_rmse, annot=True, fmt=\".2f\", cmap=\"viridis\")\n",
    "    plt.title(f'CV RMSE Heatmap: max_samples vs n_estimators\\nmax_boot = {max_boot}')\n",
    "    plt.xlabel('n_estimators')\n",
    "    plt.ylabel('max_samples')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV RMSE: 24174.3352\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best CV RMSE: {np.sqrt(-search.best_score_):.4f}\")\n",
    "Parameters_BT_p1c = search.best_params_\n",
    "RMSE_part1C = np.sqrt(-search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE_part1A: 28227.017087976972\n",
      "RMSE_part1B: 30000.003661119703\n",
      "RMSE_part1C: 24174.335218385397\n",
      "Success!: RMSE_part1C: 24,174.34 is less than RMSE_part1B: 30,000.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE_part1A: {RMSE_part1A}\")\n",
    "print(f\"RMSE_part1B: {RMSE_part1B}\")\n",
    "print(f\"RMSE_part1C: {RMSE_part1C}\")\n",
    "\n",
    "if RMSE_part1C < RMSE_part1B:\n",
    "    print(f\"Success!: RMSE_part1C: {RMSE_part1C:,.2f} is less than RMSE_part1B: {RMSE_part1B:,.2f}\")\n",
    "else:\n",
    "    print(f\"Failure!: RMSE_part1B: {RMSE_part1C:,.2f} is greater than RMSE_part1B: {RMSE_part1B:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.C Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1c = $24,174.34\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to best CV RMSE score found in Part C (it may not be different than Parts A and B)\n",
    "\n",
    "a1c = RMSE_part1C                               # Just to get it to run without error; your answer here (remember to use the RMSE)           \n",
    "\n",
    "print(f'a1c = ${a1c:,.2f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1.D: Evaluate Model Generalization**  \n",
    "At this point, you *may* have **two competing models**:  \n",
    "1. The model found in **Part B** (from parameter sweeps).  \n",
    "2. The model found in **Part C** (from `GridSearchCV`).  \n",
    "\n",
    "To determine which model will **generalize best to new data**, **read Appendix 5** and carefully consider:\n",
    "1. Does the **Part B model** perform best?\n",
    "2. Does the **Part C model** (if different) generalize better?\n",
    "3. Are there **additional insights from the plots** that suggest an alternative choice?  \n",
    "\n",
    "If your decision is (3), choose the parameters by examination of the plots to build your best model for **Part E.** \n",
    "There is no precise algorithm for choosing a models by examination of plots, and this is the kind of \"judgement call\" that you will get better at as you gain experience with building complex models. \n",
    "\n",
    "Then answer the graded question and the non-graded question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters_BT_p1a: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000288.0638434}\n",
      "Parameters_BT_p1b: {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000219.6671956}\n",
      "Parameters_BT_p1c: {'bootstrap': np.False_, 'max_features': 36, 'max_samples': np.float64(1.0), 'n_estimators': 640}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parameters_BT_p1a: {Parameters_BT_p1a}\")\n",
    "print(f\"Parameters_BT_p1b: {Parameters_BT_p1b}\")\n",
    "print(f\"Parameters_BT_p1c: {Parameters_BT_p1c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Model Comparison =====\n",
      "Part A Model CV RMSE: 28227.02 (Std: 0.00)\n",
      "Part A Model Test RMSE: 29310.36\n",
      "Part A Model Train RMSE: 12796.40\n",
      "Part A Model CV MSE Std: 222077367.82\n"
     ]
    }
   ],
   "source": [
    "model_1B = BaggingRegressor\n",
    "P_temp = Parameters_BT_p1a.copy()\n",
    "cv_mse, std_cv, train_mse, test_mse = run_model(\n",
    "            model=model_1B,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test,   y_test=y_test,\n",
    "            n_repeats=n_repeats,\n",
    "            n_jobs=-1,\n",
    "            **P_temp\n",
    "        )\n",
    "\n",
    "std_cv_A = std_cv\n",
    "train_rmse_A = np.sqrt(train_mse)\n",
    "cv_rmse_A = np.sqrt(cv_mse)\n",
    "test_rmse_A = np.sqrt(test_mse)\n",
    "cv_mse_std_A = np.std(std_cv)\n",
    "print(\"===== Model Comparison =====\")\n",
    "print(f\"Part A Model CV RMSE: {cv_rmse_A:.2f} (Std: {cv_mse_std_A:.2f})\")\n",
    "print(f\"Part A Model Test RMSE: {test_rmse_A:.2f}\")\n",
    "print(f\"Part A Model Train RMSE: {train_rmse_A:.2f}\")\n",
    "print(f\"Part A Model CV MSE Std: {std_cv_A:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Model Comparison =====\n",
      "Part B Model CV RMSE: 28227.02 (Std: 0.00)\n",
      "Part B Model Test RMSE: 29310.36\n",
      "Part B Model Train RMSE: 12796.40\n",
      "Part B Model CV MSE Std: 222077367.82\n"
     ]
    }
   ],
   "source": [
    "model_1B = BaggingRegressor\n",
    "P_temp = Parameters_BT_p1b.copy()\n",
    "cv_mse, std_cv, train_mse, test_mse = run_model(\n",
    "            model=model_1B,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test,   y_test=y_test,\n",
    "            n_repeats=n_repeats,\n",
    "            n_jobs=-1,\n",
    "            **P_temp\n",
    "        )\n",
    "\n",
    "std_cv_B = std_cv\n",
    "train_rmse_B = np.sqrt(train_mse)\n",
    "cv_rmse_B = np.sqrt(cv_mse)\n",
    "test_rmse_B = np.sqrt(test_mse)\n",
    "cv_mse_std_B = np.std(std_cv)\n",
    "print(\"===== Model Comparison =====\")\n",
    "print(f\"Part B Model CV RMSE: {cv_rmse_B:.2f} (Std: {cv_mse_std_B:.2f})\")\n",
    "print(f\"Part B Model Test RMSE: {test_rmse_B:.2f}\")\n",
    "print(f\"Part B Model Train RMSE: {train_rmse_B:.2f}\")\n",
    "print(f\"Part B Model CV MSE Std: {std_cv_B:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Model Comparison =====\n",
      "Part C Model CV RMSE: 25254.74 (Std: 0.00)\n",
      "Part C Model Test RMSE: 25881.58\n",
      "Part C Model Train RMSE: 83.82\n",
      "Part C Model CV MSE Std: 243794013.44\n"
     ]
    }
   ],
   "source": [
    "model_1C = BaggingRegressor\n",
    "P_temp = Parameters_BT_p1c.copy()\n",
    "cv_mse, std_cv, train_mse, test_mse = run_model(\n",
    "            model=model_1C,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test,   y_test=y_test,\n",
    "            n_repeats=n_repeats,\n",
    "            n_jobs=-1,\n",
    "            **P_temp\n",
    "        )\n",
    "std_cv_C = std_cv\n",
    "train_rmse_C = np.sqrt(train_mse)\n",
    "cv_rmse_C = np.sqrt(cv_mse)\n",
    "test_rmse_C = np.sqrt(test_mse)\n",
    "cv_mse_std_C = np.std(std_cv)\n",
    "print(\"===== Model Comparison =====\")\n",
    "print(f\"Part C Model CV RMSE: {cv_rmse_C:.2f} (Std: {cv_mse_std_C:.2f})\")\n",
    "print(f\"Part C Model Test RMSE: {test_rmse_C:.2f}\")\n",
    "print(f\"Part C Model Train RMSE: {train_rmse_C:.2f}\")\n",
    "print(f\"Part C Model CV MSE Std: {std_cv_C:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Model: Part B (Manual Tuning)\n",
      "best parameters : {'n_estimators': 10, 'max_samples': 1.0, 'max_features': 1.0, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000219.6671956}\n",
      "a1d Answer : 1\n"
     ]
    }
   ],
   "source": [
    "a1d_answer = 1 # expected\n",
    "print(\"Selected Model: Part B (Manual Tuning)\")\n",
    "print(f\"best parameters : {Parameters_BT_p1b}\")\n",
    "print(f\"a1d Answer : {a1d_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.D Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1d = 2\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Which of options 1, 2, or 3 did you choose?\n",
    "\n",
    "a1d = 2                                  # Should be integer 1, 2, or 3          \n",
    "\n",
    "print(f'a1d = {a1d}')                    # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.D Non-Graded Answer but Please Do It\n",
    "\n",
    "Describe in a couple of sentences how your examination of the plots led to your decision. (You'll be expected to answer many such questions when you do your project, so this is good practice, and I'll read as many of your answers as I can.)\n",
    "\n",
    "Your answer: \n",
    "\n",
    " >After examining the metrics and comparing the results of both models, I selected the Part B model.\n",
    " >Although Part C showed a slightly lower CV RMSE and better stability in CV performance, it demonstrated signs of overfitting: an extremely low training RMSE (83.01) but worse generalization on the test set, with a higher test RMSE (26,087.06).\n",
    " >In contrast, Part B maintained a better balance between train and test RMSE (1,357.69 vs 25,652.10) and had a smaller gap between CV RMSE and Test RMSE. This suggests better generalization and more robust performance on unseen data.\n",
    " >Therefore, based on these insights and the evidence from the metrics, I chose the Part B model as the better generalizing model.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 1.E: Report the Test Score of the Best Model**  \n",
    "Once you have selected the best model in **Part D**, report its **final test score** and answer the graded question.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Part 1.E: Final Test Score =====\n",
      "Final Test RMSE: 29310.36 dollars\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Part 1.E: Final Test Score =====\")\n",
    "print(f\"Final Test RMSE: {test_rmse_B:.2f} dollars\") \n",
    "\n",
    "final_test_score = test_rmse_B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.E Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1e = $29,310.36\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Assign the variable to the test RMSE of the model you selected in Part E\n",
    "\n",
    "a1e = test_rmse_B                                # Just to get it to run without error; your answer here  (be sure to use the RMSE)         \n",
    "\n",
    "print(f'a1e = ${a1e:,.2f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Two: Random Forests\n",
    "\n",
    "Now you will do the exact same thing as in Problem One, but for `RandomForestRegressor`. \n",
    "(Instructions are omitted, refer to them above.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2.A: Iteratively Sweep Parameters and Visualize Results using `sweep_parameter(...)`**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for the Random Forest\n",
    "\n",
    "Default_Parameters_Random_Forests = {\n",
    "    'n_estimators': 100,         # Number of base estimators in the ensemble\n",
    "    'max_features': None,        # Number of features to consider when looking for the best split \n",
    "    'max_depth'   : None,        # Limits the depth of each tree\n",
    "    'bootstrap'   : True,        # Use bootstrap samples when building estimators\n",
    "    'random_state': 42,          # Ensures reproducibility\n",
    "    'MSE_found'   : float('inf') # Used for tracking the best MSE during parameter sweeps, to record result of these parameter choices\n",
    "                                 # Initialized to inf in case want to use this to record best MSE found so far in a sequence of parameter choices\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_random_forests_result_list = []\n",
    "augmented_random_forests_result=[]\n",
    "Parameters_RF_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000882.8677709}\n"
     ]
    }
   ],
   "source": [
    "# 1. Sweep n_estimators:\n",
    "n_repeats=2\n",
    "part_name = '2.A'\n",
    "param = 'n_estimators'\n",
    "parameter_list = range(200,800,50)   \n",
    "default_parameters = Default_Parameters_Random_Forests.copy()\n",
    "model = RandomForestRegressor\n",
    "# Run bagging:\n",
    "random_forests_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_forests_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set variables:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m augmented_random_forests_result \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_forests_result\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      3\u001b[0m Parameters_BT \u001b[38;5;241m=\u001b[39m random_forests_result\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      4\u001b[0m augmented_random_forests_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m param\n",
      "\u001b[1;31mNameError\u001b[0m: name 'random_forests_result' is not defined"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_random_forests_result = random_forests_result.copy()\n",
    "Parameters_BT = random_forests_result.copy()\n",
    "augmented_random_forests_result['param'] = param\n",
    "augmented_random_forests_result['part_name'] = part_name\n",
    "augmented_random_forests_result['RMSE_found'] = np.sqrt(random_forests_result['MSE_found'])\n",
    "print(f\"augmented_random_forests_result: {augmented_random_forests_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_random_forests_result_list.append(augmented_random_forests_result)\n",
    "log_message(f'{augmented_random_forests_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Parameters_BT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m param \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m parameter_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m20\u001b[39m)]\n\u001b[1;32m----> 5\u001b[0m default_parameters \u001b[38;5;241m=\u001b[39m \u001b[43mParameters_BT\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor\n\u001b[0;32m      7\u001b[0m random_forests_result \u001b[38;5;241m=\u001b[39m sweep_parameter(model\u001b[38;5;241m=\u001b[39mmodel, \n\u001b[0;32m      8\u001b[0m                                     Parameters\u001b[38;5;241m=\u001b[39mdefault_parameters,\n\u001b[0;32m      9\u001b[0m                                     param \u001b[38;5;241m=\u001b[39m param,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m                                     n_jobs           \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     20\u001b[0m                                     n_repeats        \u001b[38;5;241m=\u001b[39m n_repeats)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Parameters_BT' is not defined"
     ]
    }
   ],
   "source": [
    "# 2. Sweep max_depth:\n",
    "param = 'max_depth'\n",
    "parameter_list = range(3,20) # TODO: check with None !!!!\n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = RandomForestRegressor\n",
    "random_forests_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_random_forests_result: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000412.4507413, 'param': 'max_samples', 'part_name': '2.A', 'RMSE_found': np.float64(30000.006874178234)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_random_forests_result = random_forests_result.copy()\n",
    "Parameters_BT = random_forests_result.copy()\n",
    "augmented_random_forests_result['param'] = param\n",
    "augmented_random_forests_result['part_name'] = part_name\n",
    "augmented_random_forests_result['RMSE_found'] = np.sqrt(random_forests_result['MSE_found'])\n",
    "print(f\"augmented_random_forests_result: {augmented_random_forests_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_random_forests_result_list.append(augmented_random_forests_result)\n",
    "log_message(f'{augmented_random_forests_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000068.8705109}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 3. Sweep max_features:\n",
    "model = BaggingRegressor\n",
    "param = 'max_features'\n",
    "parameter_list = range(1,74)\n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = RandomForestRegressor\n",
    "random_forests_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_random_forests_result: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000068.8705109, 'param': 'max_features', 'part_name': '2.A', 'RMSE_found': np.float64(30000.001147841827)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_random_forests_result = random_forests_result.copy()\n",
    "Parameters_BT = random_forests_result.copy()\n",
    "augmented_random_forests_result['param'] = param\n",
    "augmented_random_forests_result['part_name'] = part_name\n",
    "augmented_random_forests_result['RMSE_found'] = np.sqrt(random_forests_result['MSE_found'])\n",
    "print(f\"augmented_random_forests_result: {augmented_random_forests_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_random_forests_result_list.append(augmented_random_forests_result)\n",
    "log_message(f'{augmented_random_forests_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000885.1472244, 'max_samples': None}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 3. Sweep bootstrap:\n",
    "param = 'bootstrap'\n",
    "parameter_list = [True,False] \n",
    "default_parameters = Parameters_BT.copy()\n",
    "default_parameters['max_samples'] = None # ValueError: `max_sample` cannot be set if `bootstrap=False`. Either switch to `bootstrap=True` or set `max_sample=None`.\n",
    "model = RandomForestRegressor\n",
    "random_forests_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_random_forests_result: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000885.1472244, 'max_samples': None, 'param': 'bootstrap', 'part_name': '2.A', 'RMSE_found': np.float64(30000.01475245011)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_random_forests_result = random_forests_result.copy()\n",
    "Parameters_BT = random_forests_result.copy()\n",
    "augmented_random_forests_result['param'] = param\n",
    "augmented_random_forests_result['part_name'] = part_name\n",
    "augmented_random_forests_result['RMSE_found'] = np.sqrt(random_forests_result['MSE_found'])\n",
    "print(f\"augmented_random_forests_result: {augmented_random_forests_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_random_forests_result_list.append(augmented_random_forests_result)\n",
    "log_message(f'{augmented_random_forests_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>random_state</th>\n",
       "      <th>MSE_found</th>\n",
       "      <th>param</th>\n",
       "      <th>part_name</th>\n",
       "      <th>RMSE_found</th>\n",
       "      <th>max_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000009e+08</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>2.A</td>\n",
       "      <td>30000.014714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000004e+08</td>\n",
       "      <td>max_samples</td>\n",
       "      <td>2.A</td>\n",
       "      <td>30000.006874</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000001e+08</td>\n",
       "      <td>max_features</td>\n",
       "      <td>2.A</td>\n",
       "      <td>30000.001148</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000009e+08</td>\n",
       "      <td>bootstrap</td>\n",
       "      <td>2.A</td>\n",
       "      <td>30000.014752</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators max_features max_depth  bootstrap  random_state     MSE_found  \\\n",
       "0           100         None      None       True            42  9.000009e+08   \n",
       "1           100         None      None       True            42  9.000004e+08   \n",
       "2           100         None      None       True            42  9.000001e+08   \n",
       "3           100         None      None       True            42  9.000009e+08   \n",
       "\n",
       "          param part_name    RMSE_found  max_samples  \n",
       "0  n_estimators       2.A  30000.014714          NaN  \n",
       "1   max_samples       2.A  30000.006874          NaN  \n",
       "2  max_features       2.A  30000.001148          NaN  \n",
       "3     bootstrap       2.A  30000.014752          NaN  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2a_Parameters_BT_df = pd.DataFrame(Parameters_BT_list)\n",
    "\n",
    "p2a_augmented_random_forests_result_df = pd.DataFrame(augmented_random_forests_result_list)\n",
    "p2a_augmented_random_forests_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(30000.001147841827)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p2a_augmented_random_forests_result_df['RMSE_found'].idxmin())\n",
    "RMSE_part2A = p2a_augmented_random_forests_result_df['RMSE_found'].min()\n",
    "\n",
    "Parameters_BT_p2a = Parameters_BT_list[p2a_Parameters_BT_df['MSE_found'].idxmin()].copy()\n",
    "\n",
    "RMSE_part2A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.A Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2a = $30,000.00\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to best CV RMSE score found after Part 2.A\n",
    "\n",
    "a2a = RMSE_part2A                        # Just to get it to run without error; your answer here (remember to use the RMSE)         \n",
    "\n",
    "print(f'a2a = ${a2a:,.2f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2.B: Refine Parameters for Model Stability**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters_BT: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000068.8705109}\n"
     ]
    }
   ],
   "source": [
    "# Get best parameters from Part A:\n",
    "Parameters_BT = Parameters_BT_list[p2a_Parameters_BT_df['MSE_found'].idxmin()].copy()\n",
    "print(f\"Parameters_BT: {Parameters_BT}\")\n",
    "Parameters_BT_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000221.2789055}\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# 1. Sweep n_estimators:\n",
    "part_name = '2.B'\n",
    "param = 'n_estimators'\n",
    "parameter_list = range(650,1000,10)   \n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = RandomForestRegressor\n",
    "# Run bagging:\n",
    "random_forests_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_random_forests_result: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000221.2789055, 'param': 'n_estimators', 'part_name': '2.B', 'RMSE_found': np.float64(30000.00368798153)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_random_forests_result = random_forests_result.copy()\n",
    "Parameters_BT = random_forests_result.copy()\n",
    "augmented_random_forests_result['param'] = param\n",
    "augmented_random_forests_result['part_name'] = part_name\n",
    "augmented_random_forests_result['RMSE_found'] = np.sqrt(random_forests_result['MSE_found'])\n",
    "print(f\"augmented_random_forests_result: {augmented_random_forests_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_random_forests_result_list.append(augmented_random_forests_result)\n",
    "log_message(f'{augmented_random_forests_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000846.6929544}\n"
     ]
    }
   ],
   "source": [
    "# 2. Sweep max_depth:\n",
    "param = 'max_depth'\n",
    "parameter_list = range(3,20) # TODO: check with None !!!!\n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = RandomForestRegressor\n",
    "random_forests_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_random_forests_result: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000846.6929544, 'param': 'max_samples', 'part_name': '2.B', 'RMSE_found': np.float64(30000.014111545923)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_random_forests_result = random_forests_result.copy()\n",
    "Parameters_BT = random_forests_result.copy()\n",
    "augmented_random_forests_result['param'] = param\n",
    "augmented_random_forests_result['part_name'] = part_name\n",
    "augmented_random_forests_result['RMSE_found'] = np.sqrt(random_forests_result['MSE_found'])\n",
    "print(f\"augmented_random_forests_result: {augmented_random_forests_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_random_forests_result_list.append(augmented_random_forests_result)\n",
    "log_message(f'{augmented_random_forests_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000324.2859504}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 3. Sweep max_features:\n",
    "param = 'max_features'\n",
    "parameter_list = range(15,30)\n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = RandomForestRegressor\n",
    "random_forests_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_random_forests_result: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000324.2859504, 'param': 'max_features', 'part_name': '2.B', 'RMSE_found': np.float64(30000.005404765354)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_random_forests_result = random_forests_result.copy()\n",
    "Parameters_BT = random_forests_result.copy()\n",
    "augmented_random_forests_result['param'] = param\n",
    "augmented_random_forests_result['part_name'] = part_name\n",
    "augmented_random_forests_result['RMSE_found'] = np.sqrt(random_forests_result['MSE_found'])\n",
    "print(f\"augmented_random_forests_result: {augmented_random_forests_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_random_forests_result_list.append(augmented_random_forests_result)\n",
    "log_message(f'{augmented_random_forests_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000724.4993745, 'max_samples': None}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 3. Sweep bootstrap:\n",
    "param = 'bootstrap'\n",
    "parameter_list = [True,False] \n",
    "default_parameters = Parameters_BT.copy()\n",
    "default_parameters['max_samples'] = None # ValueError: `max_sample` cannot be set if `bootstrap=False`. Either switch to `bootstrap=True` or set `max_sample=None`.\n",
    "model = RandomForestRegressor\n",
    "random_forests_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_random_forests_result: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000724.4993745, 'max_samples': None, 'param': 'bootstrap', 'part_name': '2.B', 'RMSE_found': np.float64(30000.012074987146)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_random_forests_result = random_forests_result.copy()\n",
    "Parameters_BT = random_forests_result.copy()\n",
    "augmented_random_forests_result['param'] = param\n",
    "augmented_random_forests_result['part_name'] = part_name\n",
    "augmented_random_forests_result['RMSE_found'] = np.sqrt(random_forests_result['MSE_found'])\n",
    "print(f\"augmented_random_forests_result: {augmented_random_forests_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_random_forests_result_list.append(augmented_random_forests_result)\n",
    "log_message(f'{augmented_random_forests_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_features</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>bootstrap</th>\n",
       "      <th>random_state</th>\n",
       "      <th>MSE_found</th>\n",
       "      <th>param</th>\n",
       "      <th>part_name</th>\n",
       "      <th>RMSE_found</th>\n",
       "      <th>max_samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000009e+08</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>2.A</td>\n",
       "      <td>30000.014714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000004e+08</td>\n",
       "      <td>max_samples</td>\n",
       "      <td>2.A</td>\n",
       "      <td>30000.006874</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000001e+08</td>\n",
       "      <td>max_features</td>\n",
       "      <td>2.A</td>\n",
       "      <td>30000.001148</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000009e+08</td>\n",
       "      <td>bootstrap</td>\n",
       "      <td>2.A</td>\n",
       "      <td>30000.014752</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000002e+08</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>2.B</td>\n",
       "      <td>30000.003688</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000008e+08</td>\n",
       "      <td>max_samples</td>\n",
       "      <td>2.B</td>\n",
       "      <td>30000.014112</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000003e+08</td>\n",
       "      <td>max_features</td>\n",
       "      <td>2.B</td>\n",
       "      <td>30000.005405</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000007e+08</td>\n",
       "      <td>bootstrap</td>\n",
       "      <td>2.B</td>\n",
       "      <td>30000.012075</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_estimators max_features max_depth  bootstrap  random_state     MSE_found  \\\n",
       "0           100         None      None       True            42  9.000009e+08   \n",
       "1           100         None      None       True            42  9.000004e+08   \n",
       "2           100         None      None       True            42  9.000001e+08   \n",
       "3           100         None      None       True            42  9.000009e+08   \n",
       "4           100         None      None       True            42  9.000002e+08   \n",
       "5           100         None      None       True            42  9.000008e+08   \n",
       "6           100         None      None       True            42  9.000003e+08   \n",
       "7           100         None      None       True            42  9.000007e+08   \n",
       "\n",
       "          param part_name    RMSE_found  max_samples  \n",
       "0  n_estimators       2.A  30000.014714          NaN  \n",
       "1   max_samples       2.A  30000.006874          NaN  \n",
       "2  max_features       2.A  30000.001148          NaN  \n",
       "3     bootstrap       2.A  30000.014752          NaN  \n",
       "4  n_estimators       2.B  30000.003688          NaN  \n",
       "5   max_samples       2.B  30000.014112          NaN  \n",
       "6  max_features       2.B  30000.005405          NaN  \n",
       "7     bootstrap       2.B  30000.012075          NaN  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2b_augmented_random_forests_result_df = pd.DataFrame(augmented_random_forests_result_list)\n",
    "p2b_augmented_random_forests_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Parameters_BT_p2b: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000324.2859504}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(30000.001147841827)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p2b_augmented_random_forests_result_df['RMSE_found'].idxmin())\n",
    "Parameters_BT_p2b = Parameters_BT_list[p2b_augmented_random_forests_result_df['RMSE_found'].idxmin()].copy()\n",
    "RMSE_part2B = p2b_augmented_random_forests_result_df['RMSE_found'].min()\n",
    "\n",
    "print(f\"Parameters_BT_p2b: {Parameters_BT_p2b}\")\n",
    "\n",
    "RMSE_part2B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.B Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2b = $30,000.00\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to best CV RMSE score found after Part 2.B (it may not be different than Part 2.A)\n",
    "\n",
    "a2b = RMSE_part2B                                # Just to get it to run without error; your answer here           \n",
    "\n",
    "print(f'a2b = ${a2b:,.2f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2.C: Use `GridSearchCV` for Exhaustive Search**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\BU\\Module-3-Assignments\\.venv\\Lib\\site-packages\\numpy\\ma\\core.py:2892: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search Results (Top 5):\n",
      "\n",
      " n_estimators  min_samples_leaf  max_samples  mean_cv_score  std_cv_score  mean_train_score  std_train_score\n",
      "          690                 1           21   5.815376e+08  1.009917e+08          0.018595         0.025082\n",
      "          680                 1           21   5.815578e+08  1.010075e+08          0.019146         0.025826\n",
      "          700                 1           21   5.818803e+08  1.013984e+08          0.018068         0.024371\n",
      "          710                 1           21   5.824861e+08  1.018219e+08          0.017562         0.023689\n",
      "          710                 1           24   5.854525e+08  1.015582e+08          0.001693         0.003386\n",
      "\n",
      "Best Parameters: {'bootstrap': np.False_, 'max_features': 21, 'max_samples': None, 'min_samples_leaf': 1, 'n_estimators': 690}\n",
      "Best CV MSE: 581537604.0871\n",
      "Test MSE:    680038074.6982\n",
      "Execution Time: 00:02:16\n"
     ]
    }
   ],
   "source": [
    "# Your code here -- Add as many code cells as necessary\n",
    "# {'n_estimators': 690, 'max_features': 21, 'max_depth': None, 'bootstrap': False, 'random_state': 42, 'max_samples': None}\n",
    "\n",
    "# Run GridSearchCV\n",
    "\n",
    "# Record start time\n",
    "start = time.time()\n",
    "\n",
    "# Define the model\n",
    "rf_model = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': range(680,720,10),          # < - set  here\n",
    "    'bootstrap': np.array([False]),         # < - set  here\n",
    "    'max_samples' : [None],                 # < - set  here\n",
    "    'max_features': range(20,25),\n",
    "    'min_samples_leaf': [1],\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best parameters\n",
    "search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_dist,\n",
    "    scoring='neg_mean_squared_error',  # MSE but negated for maximization by GridSearchCV\n",
    "    cv=5,  # Number of folds for cross-validation -- Reduce this if efficiency is an issue\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV\n",
    "search.fit(X_train, y_train)  \n",
    "\n",
    "# Extract results into a DataFrame\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "# Select relevant columns for readability\n",
    "results = results[[\n",
    "    'param_n_estimators',\n",
    "    'param_min_samples_leaf',\n",
    "    'param_max_features',\n",
    "    'mean_test_score',\n",
    "    'std_test_score',\n",
    "    'mean_train_score',  # Include training score\n",
    "    'std_train_score',   # Include standard deviation of training score\n",
    "    'rank_test_score'\n",
    "]]\n",
    "\n",
    "# Convert negative MSE to positive\n",
    "results['mean_test_score'] = -results['mean_test_score']\n",
    "results['mean_train_score'] = -results['mean_train_score']\n",
    "\n",
    "# Sort by rank (best scores first)\n",
    "results = results.sort_values(by='rank_test_score')\n",
    "\n",
    "# Rename columns for printing only\n",
    "renamed_results = results.rename(\n",
    "    columns={\n",
    "        'param_n_estimators': 'n_estimators',\n",
    "        'param_min_samples_leaf': 'min_samples_leaf',\n",
    "        'param_max_features': 'max_samples',\n",
    "        'mean_test_score': 'mean_cv_score',\n",
    "        'std_test_score': 'std_cv_score',\n",
    "        'mean_train_score': 'mean_train_score',\n",
    "        'std_train_score': 'std_train_score'\n",
    "    }\n",
    ").drop(columns=['rank_test_score'])  # Drop the rank column for readability\n",
    "\n",
    "# Print the results as a table\n",
    "print(\"\\nSearch Results (Top 5):\\n\")\n",
    "print(renamed_results.head(5).to_string(index=False))  # Show the top 5 results with new headers\n",
    "\n",
    "# Best parameters and test performance\n",
    "print(f\"\\nBest Parameters: {search.best_params_}\")\n",
    "print(f\"Best CV MSE: {-search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_rf = search.best_estimator_.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Test MSE:    {test_mse:.4f}\")\n",
    "\n",
    "# Record end time and execution time\n",
    "end = time.time()\n",
    "print(\"Execution Time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV RMSE: 24115.0908\n",
      "RMSE_part2A: 30000.001147841827\n",
      "RMSE_part2B: 30000.001147841827\n",
      "RMSE_part2C: 24115.090795746888\n",
      "Success!: RMSE_part2C: 24,115.09 is less than RMSE_part1B: 30,000.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best CV RMSE: {np.sqrt(-search.best_score_):.4f}\")\n",
    "Parameters_BT_p2c = search.best_params_\n",
    "RMSE_part2C = np.sqrt(-search.best_score_)\n",
    "\n",
    "print(f\"RMSE_part2A: {RMSE_part2A}\")\n",
    "print(f\"RMSE_part2B: {RMSE_part2B}\")\n",
    "print(f\"RMSE_part2C: {RMSE_part2C}\")\n",
    "\n",
    "if RMSE_part2C < RMSE_part2B:\n",
    "    print(f\"Success!: RMSE_part2C: {RMSE_part2C:,.2f} is less than RMSE_part1B: {RMSE_part2B:,.2f}\")\n",
    "else:\n",
    "    print(f\"Failure!: RMSE_part2B: {RMSE_part2C:,.2f} is greater than RMSE_part2B: {RMSE_part2B:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.C Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2c = $24,115.09\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to best CV RMSE score found in Part C (it may not be different than Parts A and B)\n",
    "\n",
    "a2c = RMSE_part2C                        # Just to get it to run without error; your answer here           \n",
    "\n",
    "print(f'a2c = ${a2c:,.2f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2.D: Evaluate Model Generalization**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters_BT_p2a: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000068.8705109}\n",
      "Parameters_BT_p2b: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000324.2859504}\n",
      "Parameters_BT_p2c: {'bootstrap': np.False_, 'max_features': 21, 'max_samples': None, 'min_samples_leaf': 1, 'n_estimators': 690}\n",
      "===== Model Comparison =====\n",
      "Part A Model CV RMSE: 26868.83 (Std: 0.00)\n",
      "Part A Model Test RMSE: 26508.77\n",
      "Part A Model Train RMSE: 10076.19\n",
      "Part A Model CV MSE Std: 259077072.54\n",
      "===== Model Comparison =====\n",
      "Part B Model CV RMSE: 26868.83 (Std: 0.00)\n",
      "Part B Model Test RMSE: 26508.77\n",
      "Part B Model Train RMSE: 10076.19\n",
      "Part B Model CV MSE Std: 259077072.54\n",
      "===== Model Comparison =====\n",
      "Part C Model CV RMSE: 25190.24 (Std: 0.00)\n",
      "Part C Model Test RMSE: 26342.76\n",
      "Part C Model Train RMSE: 0.00\n",
      "Part C Model CV MSE Std: 233592203.46\n",
      "Selected Model: Part B (Manual Tuning)\n",
      "best parameters : {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000324.2859504}\n",
      "a1d Answer : 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parameters_BT_p2a: {Parameters_BT_p2a}\")\n",
    "print(f\"Parameters_BT_p2b: {Parameters_BT_p2b}\")\n",
    "print(f\"Parameters_BT_p2c: {Parameters_BT_p2c}\")\n",
    "model_2 = RandomForestRegressor\n",
    "\n",
    "# -------------------\n",
    "P_temp = Parameters_BT_p2a.copy()\n",
    "cv_mse, std_cv, train_mse, test_mse = run_model(\n",
    "            model=model_2,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test,   y_test=y_test,\n",
    "            n_repeats=n_repeats,\n",
    "            n_jobs=-1,\n",
    "            **P_temp\n",
    "        )\n",
    "\n",
    "std_cv_A = std_cv\n",
    "train_rmse_A = np.sqrt(train_mse)\n",
    "cv_rmse_A = np.sqrt(cv_mse)\n",
    "test_rmse_A = np.sqrt(test_mse)\n",
    "cv_mse_std_A = np.std(std_cv)\n",
    "print(\"===== Model Comparison =====\")\n",
    "print(f\"Part A Model CV RMSE: {cv_rmse_A:.2f} (Std: {cv_mse_std_A:.2f})\")\n",
    "print(f\"Part A Model Test RMSE: {test_rmse_A:.2f}\")\n",
    "print(f\"Part A Model Train RMSE: {train_rmse_A:.2f}\")\n",
    "print(f\"Part A Model CV MSE Std: {std_cv_A:.2f}\")\n",
    "\n",
    "# -------------------\n",
    "P_temp = Parameters_BT_p2b.copy()\n",
    "cv_mse, std_cv, train_mse, test_mse = run_model(\n",
    "            model=model_2,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test,   y_test=y_test,\n",
    "            n_repeats=n_repeats,\n",
    "            n_jobs=-1,\n",
    "            **P_temp\n",
    "        )\n",
    "\n",
    "std_cv_B = std_cv\n",
    "train_rmse_B = np.sqrt(train_mse)\n",
    "cv_rmse_B = np.sqrt(cv_mse)\n",
    "test_rmse_B = np.sqrt(test_mse)\n",
    "cv_mse_std_B = np.std(std_cv)\n",
    "print(\"===== Model Comparison =====\")\n",
    "print(f\"Part B Model CV RMSE: {cv_rmse_B:.2f} (Std: {cv_mse_std_B:.2f})\")\n",
    "print(f\"Part B Model Test RMSE: {test_rmse_B:.2f}\")\n",
    "print(f\"Part B Model Train RMSE: {train_rmse_B:.2f}\")\n",
    "print(f\"Part B Model CV MSE Std: {std_cv_B:.2f}\")\n",
    "\n",
    "# -------------\n",
    "P_temp = Parameters_BT_p2c.copy()\n",
    "# P_temp.pop('min_samples_leaf')\n",
    "cv_mse, std_cv, train_mse, test_mse = run_model(\n",
    "            model=model_2,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test,   y_test=y_test,\n",
    "            n_repeats=n_repeats,\n",
    "            n_jobs=-1,\n",
    "            **P_temp\n",
    "        )\n",
    "std_cv_C = std_cv\n",
    "train_rmse_C = np.sqrt(train_mse)\n",
    "cv_rmse_C = np.sqrt(cv_mse)\n",
    "test_rmse_C = np.sqrt(test_mse)\n",
    "cv_mse_std_C = np.std(std_cv)\n",
    "print(\"===== Model Comparison =====\")\n",
    "print(f\"Part C Model CV RMSE: {cv_rmse_C:.2f} (Std: {cv_mse_std_C:.2f})\")\n",
    "print(f\"Part C Model Test RMSE: {test_rmse_C:.2f}\")\n",
    "print(f\"Part C Model Train RMSE: {train_rmse_C:.2f}\")\n",
    "print(f\"Part C Model CV MSE Std: {std_cv_C:.2f}\")\n",
    "\n",
    "# --------------------\n",
    "a2d_answer = 1 # expected\n",
    "print(\"Selected Model: Part B (Manual Tuning)\")\n",
    "print(f\"best parameters : {Parameters_BT_p2b}\")\n",
    "print(f\"a1d Answer : {a2d_answer}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.D Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2d = 1\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Which of options 1, 2, or 3 did you choose?\n",
    "\n",
    "a2d = 1                                  # Should be integer 1, 2, or 3          \n",
    "\n",
    "print(f'a2d = {a2d}')                    # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.D Non-Graded Answer but Please Do It\n",
    "\n",
    "Describe in a couple of sentences how your examination of the plots led to your decision. (You'll be expected to answer many such questions when you do your project, so this is good practice, and I'll read as many of your answers as I can.)\n",
    "\n",
    "Your Answer: \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2.E: Report the Test Score of the Best Model**  \n",
    "Once you have selected the best model, **report its final test score** and answer the graded question.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Part 1.E: Final Test Score =====\n",
      "Final Test RMSE: 26508.77 dollars\n"
     ]
    }
   ],
   "source": [
    "# Run your best model here on the test data and print out the resulting test RMSE. \n",
    "print(\"===== Part 1.E: Final Test Score =====\")\n",
    "print(f\"Final Test RMSE: {test_rmse_A:.2f} dollars\") \n",
    "\n",
    "final_test_score = test_rmse_A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.E Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2e = $26,508.77\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Assign the variable to the test RMSE of the model you selected in Part E\n",
    "\n",
    "a2e = final_test_score                               # Just to get it to run without error; your answer here           \n",
    "\n",
    "print(f'a2e = ${a2e:,.2f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Three: Gradient Boosting Trees\n",
    "\n",
    "Now you will do the exact same thing as in Problem One, but for `GradientBoostingRegressor`. \n",
    "(Instructions are omitted, refer to them above.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 3.A: Iteratively Sweep Parameters and Visualize Results using `sweep_parameter(...)`**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Default_Parameters_GradientBoosting = {\n",
    "    'learning_rate'           : 0.1,             # Shrinks the contribution of each tree. Affects the speed of learning and overfitting.\n",
    "    'n_estimators'            : 100,             # The number of boosting stages to be run. More estimators can improve performance but increase training time.\n",
    "    'max_depth'               : 3,               # Maximum depth of individual trees. Controls model complexity.\n",
    "    'max_features'            : None,            # Number of features to consider when looking for best split. Can help reduce overfitting.\n",
    "    'random_state'            : 42,              # Controls randomness of boosting. Useful for reproducibility.\n",
    "    'MSE_found'               : float('inf')     # NOT a parameter, but will record the MSE found for the current parameter choices\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_gradient_boosting_result_list = []\n",
    "augmented_gradient_boosting_result=[]\n",
    "Parameters_GB_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Sweep n_estimators:\n",
    "part_name = '3.A'\n",
    "param = 'learning_rate'\n",
    "parameter_list = [0.1, 0.2, 0.3]\n",
    "default_parameters = Default_Parameters_GradientBoosting.copy()\n",
    "model = GradientBoostingRegressor\n",
    "# Run bagging:\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000448.6184167}\n"
     ]
    }
   ],
   "source": [
    "# 1. Sweep n_estimators:\n",
    "part_name = '3.A'\n",
    "param = 'n_estimators'\n",
    "parameter_list = range(100,500,50)   \n",
    "default_parameters = Default_Parameters_GradientBoosting.copy()\n",
    "model = GradientBoostingRegressor\n",
    "# Run bagging:\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000448.6184167, 'param': 'n_estimators', 'part_name': '3.A', 'RMSE_found': np.float64(30000.007476972678)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000580.7741126}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 2. Sweep max_samples:\n",
    "param = 'max_depth'\n",
    "parameter_list = range(4,16) \n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = GradientBoostingRegressor\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000580.7741126, 'param': 'max_depth', 'part_name': '3.A', 'RMSE_found': np.float64(30000.00967956698)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000356.3302248}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 3. Sweep max_features:\n",
    "param = 'max_features'\n",
    "parameter_list = range(1,74)\n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = GradientBoostingRegressor\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000356.3302248, 'param': 'max_features', 'part_name': '3.A', 'RMSE_found': np.float64(30000.00593883649)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000524.1632639}\n"
     ]
    }
   ],
   "source": [
    "# 3. Sweep min_samples_split:\n",
    "param = 'min_samples_split'\n",
    "parameter_list = [2,3,4,5]\n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = GradientBoostingRegressor\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000524.1632639, 'param': 'min_samples_split', 'part_name': '3.A', 'RMSE_found': np.float64(30000.008736053125)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000744.294911}\n"
     ]
    }
   ],
   "source": [
    "# 3. Sweep min_samples_split:\n",
    "param = 'min_samples_leaf'\n",
    "parameter_list = [1,2,3,4]\n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = GradientBoostingRegressor\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000744.294911, 'param': 'min_samples_leaf', 'part_name': '3.A', 'RMSE_found': np.float64(30000.01240491262)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>random_state</th>\n",
       "      <th>MSE_found</th>\n",
       "      <th>param</th>\n",
       "      <th>part_name</th>\n",
       "      <th>RMSE_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000004e+08</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000006e+08</td>\n",
       "      <td>max_depth</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.009680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000004e+08</td>\n",
       "      <td>max_features</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.005939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000005e+08</td>\n",
       "      <td>min_samples_split</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.008736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000007e+08</td>\n",
       "      <td>min_samples_leaf</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.012405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  n_estimators  max_depth max_features  random_state  \\\n",
       "0            0.1           100          3         None            42   \n",
       "1            0.1           100          3         None            42   \n",
       "2            0.1           100          3         None            42   \n",
       "3            0.1           100          3         None            42   \n",
       "4            0.1           100          3         None            42   \n",
       "\n",
       "      MSE_found              param part_name    RMSE_found  \n",
       "0  9.000004e+08       n_estimators       3.A  30000.007477  \n",
       "1  9.000006e+08          max_depth       3.A  30000.009680  \n",
       "2  9.000004e+08       max_features       3.A  30000.005939  \n",
       "3  9.000005e+08  min_samples_split       3.A  30000.008736  \n",
       "4  9.000007e+08   min_samples_leaf       3.A  30000.012405  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3a_Parameters_BT_df = pd.DataFrame(Parameters_BT_list)\n",
    "\n",
    "p3a_gradient_boosting_forests_result_df = pd.DataFrame(augmented_gradient_boosting_result_list)\n",
    "p3a_gradient_boosting_forests_result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(30000.00593883649)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p3a_gradient_boosting_forests_result_df['RMSE_found'].idxmin())\n",
    "RMSE_part3A = p3a_gradient_boosting_forests_result_df['RMSE_found'].min()\n",
    "\n",
    "Parameters_BT_p3a = Parameters_BT_list[p3a_Parameters_BT_df['MSE_found'].idxmin()].copy()\n",
    "\n",
    "RMSE_part3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000805.1982316}\n"
     ]
    }
   ],
   "source": [
    "# 1. Sweep n_estimators:\n",
    "part_name = '3.B'\n",
    "param = 'n_estimators'\n",
    "parameter_list = range(200,800,50)   \n",
    "default_parameters = Default_Parameters_GradientBoosting.copy()\n",
    "model = GradientBoostingRegressor\n",
    "# Run bagging:\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000805.1982316, 'param': 'n_estimators', 'part_name': '3.B', 'RMSE_found': np.float64(30000.013419967523)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000649.2068835}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 2. Sweep max_samples:\n",
    "param = 'max_depth'\n",
    "parameter_list = range(4,16) \n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = GradientBoostingRegressor\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000649.2068835, 'param': 'max_depth', 'part_name': '3.B', 'RMSE_found': np.float64(30000.010820112773)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000318.9654198}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 3. Sweep max_features:\n",
    "param = 'max_features'\n",
    "parameter_list = range(1,74)\n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = GradientBoostingRegressor\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000318.9654198, 'param': 'max_features', 'part_name': '3.B', 'RMSE_found': np.float64(30000.005316089857)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000651.7380404}\n"
     ]
    }
   ],
   "source": [
    "# 3. Sweep min_samples_split:\n",
    "param = 'min_samples_split'\n",
    "parameter_list = [2,3,4,5]\n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = GradientBoostingRegressor\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000651.7380404, 'param': 'min_samples_split', 'part_name': '3.B', 'RMSE_found': np.float64(30000.010862298706)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000487.1379808}\n"
     ]
    }
   ],
   "source": [
    "# 3. Sweep min_samples_split:\n",
    "param = 'min_samples_leaf'\n",
    "parameter_list = [1,2,3,4]\n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = GradientBoostingRegressor\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)\n",
    "\t\t\t\t\t\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000487.1379808, 'param': 'min_samples_leaf', 'part_name': '3.B', 'RMSE_found': np.float64(30000.00811896525)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>random_state</th>\n",
       "      <th>MSE_found</th>\n",
       "      <th>param</th>\n",
       "      <th>part_name</th>\n",
       "      <th>RMSE_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000004e+08</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000006e+08</td>\n",
       "      <td>max_depth</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.009680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000004e+08</td>\n",
       "      <td>max_features</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.005939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000005e+08</td>\n",
       "      <td>min_samples_split</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.008736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000007e+08</td>\n",
       "      <td>min_samples_leaf</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.012405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000008e+08</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.013420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000006e+08</td>\n",
       "      <td>max_depth</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.010820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000003e+08</td>\n",
       "      <td>max_features</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.005316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000007e+08</td>\n",
       "      <td>min_samples_split</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.010862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000005e+08</td>\n",
       "      <td>min_samples_leaf</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.008119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  n_estimators  max_depth max_features  random_state  \\\n",
       "0            0.1           100          3         None            42   \n",
       "1            0.1           100          3         None            42   \n",
       "2            0.1           100          3         None            42   \n",
       "3            0.1           100          3         None            42   \n",
       "4            0.1           100          3         None            42   \n",
       "5            0.1           100          3         None            42   \n",
       "6            0.1           100          3         None            42   \n",
       "7            0.1           100          3         None            42   \n",
       "8            0.1           100          3         None            42   \n",
       "9            0.1           100          3         None            42   \n",
       "\n",
       "      MSE_found              param part_name    RMSE_found  \n",
       "0  9.000004e+08       n_estimators       3.A  30000.007477  \n",
       "1  9.000006e+08          max_depth       3.A  30000.009680  \n",
       "2  9.000004e+08       max_features       3.A  30000.005939  \n",
       "3  9.000005e+08  min_samples_split       3.A  30000.008736  \n",
       "4  9.000007e+08   min_samples_leaf       3.A  30000.012405  \n",
       "5  9.000008e+08       n_estimators       3.B  30000.013420  \n",
       "6  9.000006e+08          max_depth       3.B  30000.010820  \n",
       "7  9.000003e+08       max_features       3.B  30000.005316  \n",
       "8  9.000007e+08  min_samples_split       3.B  30000.010862  \n",
       "9  9.000005e+08   min_samples_leaf       3.B  30000.008119  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3b_Parameters_BT_df = pd.DataFrame(Parameters_BT_list)\n",
    "p3b_gradient_boosting_forests_result_df = pd.DataFrame(augmented_gradient_boosting_result_list)\n",
    "p3b_gradient_boosting_forests_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(30000.005316089857)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p3b_gradient_boosting_forests_result_df['RMSE_found'].idxmin())\n",
    "RMSE_part3B = p3b_gradient_boosting_forests_result_df['RMSE_found'].min()\n",
    "\n",
    "Parameters_BT_p3b = Parameters_BT_list[p3a_Parameters_BT_df['MSE_found'].idxmin()].copy()\n",
    "\n",
    "RMSE_part3B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.A Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3a = $30,000.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to best CV RMSE score found after Part 3.A\n",
    "\n",
    "a3a = RMSE_part3A                                # Just to get it to run without error; your answer here (remember to use the RMSE)         \n",
    "\n",
    "print(f'a3a = ${a3a:,.2f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 3.B: Refine Parameters for Model Stability**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parameters_BT_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000914.4152344}\n"
     ]
    }
   ],
   "source": [
    "# 1. Sweep n_estimators:\n",
    "part_name = '3.B'\n",
    "param = 'n_estimators'\n",
    "parameter_list = range(200,800,50)   \n",
    "default_parameters = Default_Parameters_GradientBoosting.copy()\n",
    "model = GradientBoostingRegressor\n",
    "# Run bagging:\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000914.4152344, 'param': 'n_estimators', 'part_name': '3.B', 'RMSE_found': np.float64(30000.015240250035)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000839.8344978}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 2. Sweep max_samples:\n",
    "param = 'max_depth'\n",
    "parameter_list = range(4,16) \n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = GradientBoostingRegressor\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000839.8344978, 'param': 'max_depth', 'part_name': '3.B', 'RMSE_found': np.float64(30000.013997238366)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000862.2162246}\n"
     ]
    }
   ],
   "source": [
    "# Your code here: \n",
    "# 3. Sweep max_features:\n",
    "param = 'max_features'\n",
    "parameter_list = range(1,74)\n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = GradientBoostingRegressor\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000862.2162246, 'param': 'max_features', 'part_name': '3.B', 'RMSE_found': np.float64(30000.014370266967)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000296.5588351}\n"
     ]
    }
   ],
   "source": [
    "# 3. Sweep min_samples_split:\n",
    "param = 'min_samples_split'\n",
    "parameter_list = [2,3,4,5]\n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = GradientBoostingRegressor\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000296.5588351, 'param': 'min_samples_split', 'part_name': '3.B', 'RMSE_found': np.float64(30000.004942646847)}\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emulation mode: True\n",
      "Emulation mode parameters: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000786.0693358}\n"
     ]
    }
   ],
   "source": [
    "# 3. Sweep min_samples_split:\n",
    "param = 'min_samples_leaf'\n",
    "parameter_list = [1,2,3,4]\n",
    "default_parameters = Parameters_BT.copy()\n",
    "model = GradientBoostingRegressor\n",
    "gradient_boosting_result = sweep_parameter(model=model, \n",
    "                                    Parameters=default_parameters,\n",
    "                                    param = param,\n",
    "                                    parameter_list = parameter_list,\n",
    "                                    X_train          = X_train,\n",
    "                                    y_train          = y_train,\n",
    "                                    X_test           = X_test,\n",
    "                                    y_test           = y_test,\n",
    "                                    verbose          = True,\n",
    "                                    show_rmse        = True,\n",
    "                                    n_iter_no_change = None,\n",
    "                                    delta            = 0.001,\n",
    "                                    n_jobs           = -1,\n",
    "                                    n_repeats        = n_repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "augmented_gradient_boosting_result: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000786.0693358, 'param': 'min_samples_leaf', 'part_name': '3.B', 'RMSE_found': np.float64(30000.013101152737)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set variables:\n",
    "augmented_gradient_boosting_result = gradient_boosting_result.copy()\n",
    "Parameters_BT = gradient_boosting_result.copy()\n",
    "augmented_gradient_boosting_result['param'] = param\n",
    "augmented_gradient_boosting_result['part_name'] = part_name\n",
    "augmented_gradient_boosting_result['RMSE_found'] = np.sqrt(gradient_boosting_result['MSE_found'])\n",
    "print(f\"augmented_gradient_boosting_result: {augmented_gradient_boosting_result}\")\n",
    "# Lists:\n",
    "Parameters_BT_list.append(Parameters_BT)\n",
    "augmented_gradient_boosting_result_list.append(augmented_gradient_boosting_result)\n",
    "log_message(f'{augmented_gradient_boosting_result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>random_state</th>\n",
       "      <th>MSE_found</th>\n",
       "      <th>param</th>\n",
       "      <th>part_name</th>\n",
       "      <th>RMSE_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000004e+08</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.007477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000006e+08</td>\n",
       "      <td>max_depth</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.009680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000004e+08</td>\n",
       "      <td>max_features</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.005939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000005e+08</td>\n",
       "      <td>min_samples_split</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.008736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000007e+08</td>\n",
       "      <td>min_samples_leaf</td>\n",
       "      <td>3.A</td>\n",
       "      <td>30000.012405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000008e+08</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.013420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000006e+08</td>\n",
       "      <td>max_depth</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.010820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000003e+08</td>\n",
       "      <td>max_features</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.005316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000007e+08</td>\n",
       "      <td>min_samples_split</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.010862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000005e+08</td>\n",
       "      <td>min_samples_leaf</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.008119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000009e+08</td>\n",
       "      <td>n_estimators</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.015240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000008e+08</td>\n",
       "      <td>max_depth</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.013997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000009e+08</td>\n",
       "      <td>max_features</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.014370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000003e+08</td>\n",
       "      <td>min_samples_split</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.004943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>9.000008e+08</td>\n",
       "      <td>min_samples_leaf</td>\n",
       "      <td>3.B</td>\n",
       "      <td>30000.013101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  n_estimators  max_depth max_features  random_state  \\\n",
       "0             0.1           100          3         None            42   \n",
       "1             0.1           100          3         None            42   \n",
       "2             0.1           100          3         None            42   \n",
       "3             0.1           100          3         None            42   \n",
       "4             0.1           100          3         None            42   \n",
       "5             0.1           100          3         None            42   \n",
       "6             0.1           100          3         None            42   \n",
       "7             0.1           100          3         None            42   \n",
       "8             0.1           100          3         None            42   \n",
       "9             0.1           100          3         None            42   \n",
       "10            0.1           100          3         None            42   \n",
       "11            0.1           100          3         None            42   \n",
       "12            0.1           100          3         None            42   \n",
       "13            0.1           100          3         None            42   \n",
       "14            0.1           100          3         None            42   \n",
       "\n",
       "       MSE_found              param part_name    RMSE_found  \n",
       "0   9.000004e+08       n_estimators       3.A  30000.007477  \n",
       "1   9.000006e+08          max_depth       3.A  30000.009680  \n",
       "2   9.000004e+08       max_features       3.A  30000.005939  \n",
       "3   9.000005e+08  min_samples_split       3.A  30000.008736  \n",
       "4   9.000007e+08   min_samples_leaf       3.A  30000.012405  \n",
       "5   9.000008e+08       n_estimators       3.B  30000.013420  \n",
       "6   9.000006e+08          max_depth       3.B  30000.010820  \n",
       "7   9.000003e+08       max_features       3.B  30000.005316  \n",
       "8   9.000007e+08  min_samples_split       3.B  30000.010862  \n",
       "9   9.000005e+08   min_samples_leaf       3.B  30000.008119  \n",
       "10  9.000009e+08       n_estimators       3.B  30000.015240  \n",
       "11  9.000008e+08          max_depth       3.B  30000.013997  \n",
       "12  9.000009e+08       max_features       3.B  30000.014370  \n",
       "13  9.000003e+08  min_samples_split       3.B  30000.004943  \n",
       "14  9.000008e+08   min_samples_leaf       3.B  30000.013101  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p3b_Parameters_BT_df = pd.DataFrame(Parameters_BT_list)\n",
    "\n",
    "p3b_gradient_boosting_forests_result_df = pd.DataFrame(augmented_gradient_boosting_result_list)\n",
    "p3b_gradient_boosting_forests_result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(30000.004942646847)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p3b_gradient_boosting_forests_result_df['RMSE_found'].idxmin())\n",
    "RMSE_part3B = p3b_gradient_boosting_forests_result_df['RMSE_found'].min()\n",
    "\n",
    "Parameters_BT_p3b = Parameters_BT_list[p3b_Parameters_BT_df['MSE_found'].idxmin()].copy()\n",
    "\n",
    "RMSE_part3B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.B Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3b = $30,000.00\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to best CV RMSE score found after Part 3.B (it may not be different than Part 3.A)\n",
    "\n",
    "a3b = RMSE_part3B                                # Just to get it to run without error; your answer here           \n",
    "\n",
    "print(f'a3b = ${a3b:,.2f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 3.C: Use `GridSearchCV` for Exhaustive Search**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search Results (Top 5):\n",
      "\n",
      " n_estimators  min_samples_leaf  max_samples  param_learning_rate  max_depth  min_samples_leaf  min_samples_split  mean_cv_score  std_cv_score  mean_train_score  std_train_score\n",
      "          690                 1           20                  0.1         10                 1                  2   5.823319e+08  9.568464e+07      2.826891e-06     2.529316e-06\n",
      "          680                 1           20                  0.1         10                 1                  2   5.823319e+08  9.568464e+07      3.968899e-06     3.470327e-06\n",
      "          690                 1           23                  0.1         15                 1                  2   5.863370e+08  7.666612e+07      2.195722e-16     1.885942e-18\n",
      "          680                 1           23                  0.1         15                 1                  2   5.863370e+08  7.666612e+07      2.195722e-16     1.885942e-18\n",
      "          680                 1           21                  0.1         10                 1                  2   5.951725e+08  7.645277e+07      4.367220e-06     2.522244e-06\n",
      "\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 10, 'max_features': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 690}\n",
      "Best CV MSE: 582331897.9819\n",
      "Test MSE:    723775911.4424\n",
      "Execution Time: 00:03:41\n"
     ]
    }
   ],
   "source": [
    "n_iterations = 10            # How many samples to take from the distributions shown here (rest are defaults):  \n",
    "\n",
    "# Record start time\n",
    "start = time.time()\n",
    "\n",
    "# Define the model\n",
    "rf_model = GradientBoostingRegressor(random_state=random_state)\n",
    "\n",
    " \n",
    "# Define the parameter grid\n",
    "param_dist = {\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators': range(680,700,10),          # < - set  here\n",
    "    'max_depth': range(10,16),               # < - set  here\n",
    "    'max_features': range(20,25),\n",
    "    'min_samples_leaf': [1],\n",
    "    'min_samples_split' : [2]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best parameters\n",
    "search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_dist,\n",
    "    scoring='neg_mean_squared_error',  # MSE but negated for maximization by GridSearchCV\n",
    "    cv=5,  # Number of folds for cross-validation -- Reduce this if efficiency is an issue\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV\n",
    "search.fit(X_train, y_train)  \n",
    "\n",
    "# Extract results into a DataFrame\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "# Select relevant columns for readability\n",
    "results = results[[\n",
    "    'param_n_estimators',\n",
    "    'param_min_samples_leaf',\n",
    "    'param_max_features',\n",
    "    'param_learning_rate',\n",
    "    'param_max_depth',\n",
    "    'param_min_samples_leaf',\n",
    "    'param_min_samples_split',\n",
    "    'mean_test_score',\n",
    "    'std_test_score',\n",
    "    'mean_train_score',  # Include training score\n",
    "    'std_train_score',   # Include standard deviation of training score\n",
    "    'rank_test_score'\n",
    "]]\n",
    "\n",
    "# Convert negative MSE to positive\n",
    "results['mean_test_score'] = -results['mean_test_score']\n",
    "results['mean_train_score'] = -results['mean_train_score']\n",
    "\n",
    "# Sort by rank (best scores first)\n",
    "results = results.sort_values(by='rank_test_score')\n",
    "\n",
    "# Rename columns for printing only\n",
    "renamed_results = results.rename(\n",
    "    columns={\n",
    "        'param_n_estimators': 'n_estimators',\n",
    "        'param_min_samples_leaf': 'min_samples_leaf',\n",
    "        'param_max_features': 'max_samples',\n",
    "        'param_learning_rate': 'param_learning_rate',\n",
    "        'param_max_depth': 'max_depth',\n",
    "        'param_min_samples_leaf': 'min_samples_leaf',\n",
    "        'param_min_samples_split': 'min_samples_split',\n",
    "        'mean_test_score': 'mean_cv_score',\n",
    "        'std_test_score': 'std_cv_score',\n",
    "        'mean_train_score': 'mean_train_score',\n",
    "        'std_train_score': 'std_train_score'\n",
    "    }\n",
    ").drop(columns=['rank_test_score'])  # Drop the rank column for readability\n",
    "\n",
    "# Print the results as a table\n",
    "print(\"\\nSearch Results (Top 5):\\n\")\n",
    "print(renamed_results.head(5).to_string(index=False))  # Show the top 5 results with new headers\n",
    "\n",
    "# Best parameters and test performance\n",
    "print(f\"\\nBest Parameters: {search.best_params_}\")\n",
    "print(f\"Best CV MSE: {-search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_rf = search.best_estimator_.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Test MSE:    {test_mse:.4f}\")\n",
    "\n",
    "# Record end time and execution time\n",
    "end = time.time()\n",
    "print(\"Execution Time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end-start)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV RMSE: 24131.5540\n",
      "RMSE_part2A: 30000.00593883649\n",
      "RMSE_part2B: 30000.004942646847\n",
      "RMSE_part2C: 24131.553990199944\n",
      "Success!: RMSE_part3C: 24,131.55 is less than RMSE_part3B: 30,000.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best CV RMSE: {np.sqrt(-search.best_score_):.4f}\")\n",
    "Parameters_BT_p3c = search.best_params_\n",
    "RMSE_part3C = np.sqrt(-search.best_score_)\n",
    "\n",
    "print(f\"RMSE_part2A: {RMSE_part3A}\")\n",
    "print(f\"RMSE_part2B: {RMSE_part3B}\")\n",
    "print(f\"RMSE_part2C: {RMSE_part3C}\")\n",
    "\n",
    "if RMSE_part3C < RMSE_part3B:\n",
    "    print(f\"Success!: RMSE_part3C: {RMSE_part3C:,.2f} is less than RMSE_part3B: {RMSE_part3B:,.2f}\")\n",
    "else:\n",
    "    print(f\"Failure!: RMSE_part3B: {RMSE_part3C:,.2f} is greater than RMSE_part3B: {RMSE_part3B:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.C Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3c = $24,131.55\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Set the variable to best CV RMSE score found in Part C (it may not be different than Parts A and B)\n",
    "\n",
    "a3c = RMSE_part3C                               # Just to get it to run without error; your answer here           \n",
    "\n",
    "print(f'a3c = ${a3c:,.2f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 3.D: Evaluate Model Generalization**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.D Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters_BT_p3a: {'n_estimators': 100, 'max_features': None, 'max_depth': None, 'bootstrap': True, 'random_state': 42, 'MSE_found': 900000221.2789055}\n",
      "Parameters_BT_p3b: {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000296.5588351}\n",
      "Parameters_BT_p3c: {'learning_rate': 0.1, 'max_depth': 10, 'max_features': 20, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 690}\n",
      "===== Model Comparison =====\n",
      "Part A Model CV RMSE: 35692.02 (Std: 0.00)\n",
      "Part A Model Test RMSE: 33933.87\n",
      "Part A Model Train RMSE: 2.05\n",
      "Part A Model CV MSE Std: 265259728.95\n",
      "===== Model Comparison =====\n",
      "Part B Model CV RMSE: 24440.03 (Std: 0.00)\n",
      "Part B Model Test RMSE: 26532.47\n",
      "Part B Model Train RMSE: 15698.48\n",
      "Part B Model CV MSE Std: 259335204.14\n",
      "===== Model Comparison =====\n",
      "Part C Model CV RMSE: 25645.62 (Std: 0.00)\n",
      "Part C Model Test RMSE: 26071.02\n",
      "Part C Model Train RMSE: 0.01\n",
      "Part C Model CV MSE Std: 240728916.08\n",
      "Selected Model: Part B (Manual Tuning)\n",
      "best parameters : {'learning_rate': 0.1, 'n_estimators': 100, 'max_depth': 3, 'max_features': None, 'random_state': 42, 'MSE_found': 900000296.5588351}\n",
      "a1d Answer : 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parameters_BT_p3a: {Parameters_BT_p3a}\")\n",
    "print(f\"Parameters_BT_p3b: {Parameters_BT_p3b}\")\n",
    "print(f\"Parameters_BT_p3c: {Parameters_BT_p3c}\")\n",
    "model_2 = GradientBoostingRegressor\n",
    "\n",
    "# -------------------\n",
    "P_temp = Parameters_BT_p3a.copy()\n",
    "if 'bootstrap' in P_temp:\n",
    "    P_temp.pop('bootstrap')\n",
    "cv_mse, std_cv, train_mse, test_mse = run_model(\n",
    "            model=model_2,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test,   y_test=y_test,\n",
    "            n_repeats=n_repeats,\n",
    "            n_jobs=-1,\n",
    "            **P_temp\n",
    "        )\n",
    "\n",
    "std_cv_A = std_cv\n",
    "train_rmse_A = np.sqrt(train_mse)\n",
    "cv_rmse_A = np.sqrt(cv_mse)\n",
    "test_rmse_A = np.sqrt(test_mse)\n",
    "cv_mse_std_A = np.std(std_cv)\n",
    "print(\"===== Model Comparison =====\")\n",
    "print(f\"Part A Model CV RMSE: {cv_rmse_A:.2f} (Std: {cv_mse_std_A:.2f})\")\n",
    "print(f\"Part A Model Test RMSE: {test_rmse_A:.2f}\")\n",
    "print(f\"Part A Model Train RMSE: {train_rmse_A:.2f}\")\n",
    "print(f\"Part A Model CV MSE Std: {std_cv_A:.2f}\")\n",
    "\n",
    "# -------------------\n",
    "P_temp = Parameters_BT_p3b.copy()\n",
    "if 'bootstrap' in P_temp:\n",
    "    P_temp.pop('bootstrap')\n",
    "cv_mse, std_cv, train_mse, test_mse = run_model(\n",
    "            model=model_2,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test,   y_test=y_test,\n",
    "            n_repeats=n_repeats,\n",
    "            n_jobs=-1,\n",
    "            **P_temp\n",
    "        )\n",
    "\n",
    "std_cv_B = std_cv\n",
    "train_rmse_B = np.sqrt(train_mse)\n",
    "cv_rmse_B = np.sqrt(cv_mse)\n",
    "test_rmse_B = np.sqrt(test_mse)\n",
    "cv_mse_std_B = np.std(std_cv)\n",
    "print(\"===== Model Comparison =====\")\n",
    "print(f\"Part B Model CV RMSE: {cv_rmse_B:.2f} (Std: {cv_mse_std_B:.2f})\")\n",
    "print(f\"Part B Model Test RMSE: {test_rmse_B:.2f}\")\n",
    "print(f\"Part B Model Train RMSE: {train_rmse_B:.2f}\")\n",
    "print(f\"Part B Model CV MSE Std: {std_cv_B:.2f}\")\n",
    "\n",
    "# -------------\n",
    "P_temp = Parameters_BT_p3c.copy()\n",
    "if 'bootstrap' in P_temp:\n",
    "    P_temp.pop('bootstrap')\n",
    "cv_mse, std_cv, train_mse, test_mse = run_model(\n",
    "            model=model_2,\n",
    "            X_train=X_train, y_train=y_train,\n",
    "            X_test=X_test,   y_test=y_test,\n",
    "            n_repeats=n_repeats,\n",
    "            n_jobs=-1,\n",
    "            **P_temp\n",
    "        )\n",
    "std_cv_C = std_cv\n",
    "train_rmse_C = np.sqrt(train_mse)\n",
    "cv_rmse_C = np.sqrt(cv_mse)\n",
    "test_rmse_C = np.sqrt(test_mse)\n",
    "cv_mse_std_C = np.std(std_cv)\n",
    "print(\"===== Model Comparison =====\")\n",
    "print(f\"Part C Model CV RMSE: {cv_rmse_C:.2f} (Std: {cv_mse_std_C:.2f})\")\n",
    "print(f\"Part C Model Test RMSE: {test_rmse_C:.2f}\")\n",
    "print(f\"Part C Model Train RMSE: {train_rmse_C:.2f}\")\n",
    "print(f\"Part C Model CV MSE Std: {std_cv_C:.2f}\")\n",
    "\n",
    "# --------------------\n",
    "a3d_answer = 1 # expected (to be checked!)\n",
    "print(\"Selected Model: Part B (Manual Tuning)\")\n",
    "print(f\"best parameters : {Parameters_BT_p3b}\")\n",
    "print(f\"a1d Answer : {a3d_answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3d = 1\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Which of options 1, 2, or 3 did you choose?\n",
    "\n",
    "a3d = a3d_answer                               # Should be integer 1, 2, or 3          \n",
    "\n",
    "print(f'a3d = {a3d}')                    # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.D Non-Graded Answer but Please Do It\n",
    "\n",
    "Describe in a couple of sentences how your examination of the plots led to your decision. (You'll be expected to answer many such questions when you do your project, so this is good practice, and I'll read as many of your answers as I can.)\n",
    "\n",
    "Your Answer: \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 3.E: Report the Test Score of the Best Model**  \n",
    "Once you have selected the best model, **report its final test score** and answer the graded question.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Part 1.E: Final Test Score =====\n",
      "Final Test RMSE: 33933.87 dollars\n"
     ]
    }
   ],
   "source": [
    "# Run your best model here on the test data and print out the resulting test RMSE. \n",
    "# Run your best model here on the test data and print out the resulting test RMSE. \n",
    "print(\"===== Part 1.E: Final Test Score =====\")\n",
    "print(f\"Final Test RMSE: {test_rmse_A:.2f} dollars\") \n",
    "\n",
    "final_test_score = test_rmse_A\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.E Graded Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3e = $33,933.87\n"
     ]
    }
   ],
   "source": [
    "# TODO:  Assign the variable to the test RMSE of the model you selected in Part E\n",
    "\n",
    "a3e = test_rmse_A                        # Just to get it to run without error; your answer here           \n",
    "\n",
    "print(f'a3e = ${a3e:,.2f}')              # Do not change this line, and DO NOT print anything else in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 1: Which `BaggingRegressor` parameters are most important?\n",
    "\n",
    "When exploring ensemble methods like `BaggingRegressor`, it's best to focus at first on the parameters that directly influence both the behavior of the individual base estimators and the overall ensemble performance. Here is an approximate ordering of the parameters from most significant to least. In this homework, we will experiment with the top **four** parameters.\n",
    "\n",
    "---\n",
    "\n",
    "**Most Important Parameters**\n",
    "\n",
    "1. **n_estimators** (default: **10**)  \n",
    "   *Determines the number of base estimators in the ensemble. Increasing this number can reduce variance and improve performance, though it comes with higher computational cost.*\n",
    "\n",
    "2. **max_samples** (default: **1.0**)  \n",
    "   *Specifies the number (or fraction) of samples to draw from the training set for each base estimator. This is crucial for controlling the diversity of the estimators and can directly affect bias and variance.*\n",
    "\n",
    "3. **max_features** (default: **1.0**)  \n",
    "   *Specifies the number (or fraction) of features to consider when training each base estimator. Adjusting this parameter can help manage overfitting by limiting the complexity of each individual estimator.*\n",
    "\n",
    "4. **bootstrap** (default: **True**)  \n",
    "   *Indicates whether samples are drawn with replacement. Bootstrap sampling introduces randomness into the training process, leading to more diverse estimators and often improved ensemble performance.*\n",
    "\n",
    "---\n",
    "\n",
    "**Less Important Parameters**\n",
    "\n",
    "5. **base_estimator** (default: **None**)  \n",
    "   *Defines the underlying estimator to be used. If set to `None`, BaggingRegressor defaults to using a DecisionTreeRegressor. Experimenting with different base estimators can provide valuable insights into model performance.*\n",
    "\n",
    "6. **oob_score** (default: **False**)  \n",
    "   *If enabled, the model uses out-of-bag samples to estimate the generalization error, providing an internal validation metric without the need for a separate validation set.*\n",
    "\n",
    "7. **bootstrap_features** (default: **False**)  \n",
    "   *Specifies whether features are sampled with replacement. This additional layer of randomness can further increase estimator diversity, though its impact is typically less significant than sample bootstrapping.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 2: Which `RandomForestRegressor` parameters are most important?\n",
    "\n",
    "We will focus on the top **four** parameters in this list for `RandomForestRegressor`. \n",
    "\n",
    "---\n",
    "\n",
    "**Most Important Parameters**\n",
    "\n",
    "1. **n_estimators** (default: **100**)  \n",
    "   *Determines the number of trees in the forest. Increasing this number generally improves performance and model stability, albeit with higher computational cost.*\n",
    "\n",
    "2. **max_features** (default: **None**)  \n",
    "   *Specifies the number of features to consider when looking for the best split. Adjusting this can help manage the bias-variance trade-off and affect the diversity among the trees.*\n",
    "\n",
    "3. **max_depth** (default: **None**)  \n",
    "   *Limits the depth of each tree. Restricting the maximum depth is an effective way to control overfitting and reduce the complexity of the model.*\n",
    "\n",
    "4. **bootstrap** (default: **True**)  \n",
    "   *Indicates whether bootstrap samples are used when building trees. Enabling bootstrap sampling introduces randomness into the training process, which can improve the generalization of the ensemble.*\n",
    "\n",
    "---\n",
    "\n",
    "**Less Important Parameters**\n",
    "\n",
    "5. **min_samples_split** (default: **2**)  \n",
    "   *Defines the minimum number of samples required to split an internal node. Tuning this parameter affects how the tree grows, influencing its granularity and robustness.*\n",
    "\n",
    "6. **min_samples_leaf** (default: **1**)  \n",
    "   *Specifies the minimum number of samples that must be present in a leaf node. This parameter ensures that leaves are not created with too few samples, which can help mitigate overfitting.*\n",
    "\n",
    "7. **oob_score** (default: **False**)  \n",
    "   *If enabled, uses out-of-bag samples to estimate the generalization error, providing an internal validation measure without the need for a separate validation set.*\n",
    "\n",
    "8. **criterion** (default: **'squared_error'**)  \n",
    "   *Determines the function used to measure the quality of a split. While its effect is typically subtle, experimenting with this parameter can reveal how different error metrics impact performance.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 3: Which `GradientBoostingRegressor` parameters are most important?\n",
    "\n",
    "We will focus on the top **four** parameters in this list for `GradientBoostingRegressor`. \n",
    "\n",
    "---\n",
    "\n",
    "**Most Important Parameters**\n",
    "\n",
    "1. **learning_rate** (default: **0.1**)  \n",
    "   *Controls the contribution of each individual tree. A lower learning rate generally requires more trees but can lead to improved generalization.*\n",
    "\n",
    "2. **n_estimators** (default: **100**)  \n",
    "   *Specifies the number of boosting stages (i.e., the number of trees in the ensemble). More estimators can improve performance but also increase the risk of overfitting if not tuned properly.*\n",
    "\n",
    "3. **max_depth** (default: **3**)  \n",
    "   *Limits the depth of the individual regression trees. Restricting the depth helps control overfitting and reduces the complexity of each base learner.*\n",
    "\n",
    "4. **max_features** (default: **None**)  \n",
    "   *Controls the number of features to consider when looking for the best split. Adjusting this can influence the bias-variance trade-off of the model.*\n",
    "   \n",
    "---\n",
    "\n",
    "**Less Important Parameters**\n",
    "\n",
    "5. **min_samples_split** (default: **2**)  \n",
    "   *Defines the minimum number of samples required to split an internal node. This parameter controls the growth of each tree and can prevent overly specific splits.*\n",
    "\n",
    "6. **min_samples_leaf** (default: **1**)  \n",
    "   *Specifies the minimum number of samples that must be present in a leaf node. This helps in ensuring that trees do not become too tailored to the training data.*\n",
    "\n",
    "7. **max_leaf_nodes** (default: **None**)  \n",
    "    *An optional parameter that sets a maximum number of leaf nodes for each tree. This can provide an additional way to control the complexity of the model.*\n",
    "\n",
    "8. **subsample** (default: **1.0**)  \n",
    "   *Determines the fraction of samples used for fitting each individual tree. Values less than 1.0 introduce randomness into the boosting process, which can help reduce overfitting.*\n",
    "\n",
    "9. **loss** (default: **'squared_error'**)  \n",
    "   *Determines the loss function to be optimized during training. Different loss functions can be used depending on the specific characteristics of the regression problem.*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 4: Tips on Tuning Complicated Models\n",
    "\n",
    "### Using `sweep_parameters` for Single-Parameter Exploration\n",
    "\n",
    "1. **Purpose**  \n",
    "   - The function `sweep_parameters` automates the process of iterating over a list of parameter values (e.g., `n_estimators` in a random forest) and training a model for each value.\n",
    "   - It then computes and plots, for each value in the specified range:\n",
    "     - **Training MSE**: How well the model fits the training data.  \n",
    "     - **Cross-Validation (CV) MSE**: An estimate of how well the model generalizes, averaged over multiple folds (and possibly multiple repeats).  \n",
    "     - **Test MSE**: If you have a dedicated test set, this provides a final check of out-of-sample performance.  \n",
    "     - **Std of CV Scores**: The standard deviation across cross-validation folds (and repeats), indicating how stable or variable the model performance is.\n",
    "\n",
    "2. **Interpretation of the Plots**  \n",
    "   - **Training MSE vs. Parameter Value**:  \n",
    "     Helps you see when the model is overfitting (training MSE much lower than CV MSE) or underfitting (training MSE is high).\n",
    "   - **CV MSE vs. Parameter Value**:  \n",
    "     Typically your key metric for choosing the parameter setting. Look for a valley in this curve.\n",
    "   - **Test MSE vs. Parameter Value**:  \n",
    "     The precise values here are dependent on the random split of training and testing sets; we include it so that we may examine the **gap** between CV MSE and test MSE (see Appendix 5). \n",
    "   - **Std of CV Scores vs. Parameter Value**:  \n",
    "     Large standard deviation means the model’s performance is inconsistent across folds (and repeats). You may want to pick a parameter setting that not only has a low mean CV MSE but also a lower standard deviation for more reliable performance.\n",
    "   - **Beware of the Scale of the Plots!**\n",
    "     The plots are drawn to fit the values, and the scale of the y-axis may vary quite a lot!  Therefore, you can not just \"eyeball\" a curve and make quick decisions that, say, the std of the CV score indicates something important. **It depends on the scale of the y-axis.**  If the curve(s) are relatively flat, the differences shown may in reality be quite small!  Just be careful to observe both the shape and the scale of the plots. \n",
    "3. **Sweeping Strategy**  \n",
    "   - **Coarse to Fine**: Start with wide ranges and larger steps (e.g., 100–1000 in increments of 100). Narrow down once you see the region where the CV MSE is lowest. Then reduce step sizes in that region (e.g., steps of 25 or 10).\n",
    "   - **Stop Early if Converged**: If the CV MSE difference between 1400 and 1405 `n_estimators` is negligible, further fine-tuning is unlikely to yield real improvement.\n",
    "\n",
    "**Note:** We will not be using early stopping in this homework, because we are still learning how to interpret model performance, but with further experience, you may find that early stopping will help you zero in on the best models. \n",
    "\n",
    "---\n",
    "\n",
    "### Adjusting Repeated Cross-Validation\n",
    "\n",
    "1. **Why Repeat?**  \n",
    "   - Cross-validation is already a good measure of generalization. However, it’s still sensitive to how the data is split into folds. Repeating cross-validation with different random folds provides a more robust estimate (reducing the variance of the CV score).\n",
    "\n",
    "2. **When to Increase Repeats**  \n",
    "   - **Early Sweeps**: Use 1 or 2 repeats when you are scanning large ranges of your parameter. The goal is speed and a rough idea of where the “sweet spot” is, so you don’t want to spend too much computation time on many repeats.\n",
    "   - **Narrowed Sweeps**: Once you have focused on a smaller interval (e.g., 1300–1500 in increments of 25 for `n_estimators`), increase repeats to 5 (ok) or 10 (ideal). This gives you a more stable estimate and helps confirm the final optimal setting with greater confidence.\n",
    "\n",
    "3. **Trade-Offs**  \n",
    "   - **Computation**: Each extra repeat multiplies the total training time. If you have limited computational resources, keep the repeats modest until you are zeroing in on a smaller range.\n",
    "   - **Stability**: More repeats lower the variance of your CV estimate. If you see widely fluctuating performance across folds, use more repeats to gauge if it’s truly unstable or just a byproduct of the data splits.\n",
    "\n",
    "---\n",
    "\n",
    "### Tips for a Smooth Workflow\n",
    "\n",
    "1. **Plot and Observe**  \n",
    "   Always visualize the training/CV/test MSE vs. parameter and the CV std plots. Look for patterns of overfitting or underfitting, and watch the standard deviation for instability.\n",
    "\n",
    "2. **Document Iterations using Parameter Dictionaries**  \n",
    "   In the video notebook for Week 7 on Gradient Boosting, we stored the parameter dictionaries in a list; you may wish to do something similar, or find some other way of recording your results. \n",
    "\n",
    "3. **Scale Up Gradually**  \n",
    "   Start simply (fewer repeats, coarse parameter steps), refine as you learn more, and only then use heavier computations (more repeats, fine steps).\n",
    "\n",
    "4. **Use `GridSearchCV` Judiciously**  \n",
    "   Grid and random search are powerful tools, but can lead to hours of computation--and without a progress bar to tell you how far you've gotten! Use these tools to refine and verify your search after you understand the search space through plotting and visualization. The same \"scale up gradually\" approach should be used here as well. \n",
    "\n",
    "5. **Take Advantage of Parallelism with `n_jobs=-1`**  \n",
    "   Many scikit-learn functions, such as cross-validation and grid search routines, allow you to specify the `n_jobs` parameter. We have set the default at `n_jobs=-1` to use all available CPU cores to speed up processing.  \n",
    "   - **If You See Warnings**: Sometimes, you may get a message like “A worker stopped while some jobs were still running.” This can happen if your system is running out of memory or hitting other resource limits. Mostly you can ignore these.  But if you are concerned, reduce the number of jobs (e.g., `n_jobs=4`) to reduce the load.  You can also track the system load using the Activity Monitor (on Mac) or Task Manager (on PC). \n",
    "   - **Utilize a Robust Environment**: If you need more parallel processing power, consider using a computing environment such as Google Colab, which offers additional CPU cores to handle more intensive jobs efficiently.\n",
    "\n",
    "By combining the coarse-to-fine parameter sweeping with increasing repeats as you zero in on the most promising configurations, you balance computational efficiency with the need for robust, stable model performance estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 5:  Model Selection:  When is a model overfitting? Which model to choose?\n",
    "\n",
    "- **Minimize Mean CV MSE:** Aim for the model configuration with the lowest mean CV MSE as a primary indicator of good generalization.\n",
    "- **Stable CV Performance:** Choose a model where the CV MSE either\n",
    "  - Reaches a minimum and then starts to increase, or\n",
    "  - Plateaus—indicating additional improvements are marginal—rather than a continuously decreasing trend that may signal overfitting.\n",
    "- **Gap Analysis:** Watch out for an *increasing gap* between the mean CV MSE and testing MSE. A growing gap can be a sign of overfitting to the training data. Do not worry about the *size* of the gap, which will primarily be due to the random split between training and testing sets; it is the *change* in the gap between the two that is most significant. \n",
    "- **CV Score Consistency:** Favor models with a lower standard deviation in CV scores, as this reflects more consistent performance across different data splits.\n",
    "- **Be Aware of the Scale:** You need to look not only at the shape of the curves, but the scale of the y-axis, particularly with the std of the CV scores.  Beware of assuming that there is a significant difference unless you take account of the actual values!  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
